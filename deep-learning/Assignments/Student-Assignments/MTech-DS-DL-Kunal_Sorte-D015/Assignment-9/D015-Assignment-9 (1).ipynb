{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-03T17:53:28.726064Z","iopub.execute_input":"2022-11-03T17:53:28.727011Z","iopub.status.idle":"2022-11-03T17:53:30.451179Z","shell.execute_reply.started":"2022-11-03T17:53:28.726923Z","shell.execute_reply":"2022-11-03T17:53:30.450159Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Limiting the number of images per class to 400","metadata":{}},{"cell_type":"code","source":"root = '../input/emotion-detection-fer'\ntrain_path = os.path.join(root, 'train')","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:30.457106Z","iopub.execute_input":"2022-11-03T17:53:30.457631Z","iopub.status.idle":"2022-11-03T17:53:30.462887Z","shell.execute_reply.started":"2022-11-03T17:53:30.457593Z","shell.execute_reply":"2022-11-03T17:53:30.461977Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"files_train = list()\nfiles_test = list()\nemotion_train = list()\nemotion_test = list()\nfor i in os.listdir(train_path):\n    path = os.path.join(train_path, i)\n    for j in range(400):\n        if j<=(0.8*400):\n            files_train.append(os.path.join(i, os.listdir(path)[j]))\n            emotion_train.append(i)\n        else:\n            files_test.append(os.path.join(i, os.listdir(path)[j]))\n            emotion_test.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:30.464287Z","iopub.execute_input":"2022-11-03T17:53:30.464880Z","iopub.status.idle":"2022-11-03T17:53:34.216462Z","shell.execute_reply.started":"2022-11-03T17:53:30.464845Z","shell.execute_reply":"2022-11-03T17:53:34.215471Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.DataFrame([files_train, emotion_train]).T\ntest = pd.DataFrame([files_test, emotion_test]).T\ntrain.columns=['filename', 'class']\ntest.columns=['filename', 'class']","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:34.219927Z","iopub.execute_input":"2022-11-03T17:53:34.220278Z","iopub.status.idle":"2022-11-03T17:53:34.310363Z","shell.execute_reply.started":"2022-11-03T17:53:34.220243Z","shell.execute_reply":"2022-11-03T17:53:34.309259Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:34.311669Z","iopub.execute_input":"2022-11-03T17:53:34.312032Z","iopub.status.idle":"2022-11-03T17:53:34.326234Z","shell.execute_reply.started":"2022-11-03T17:53:34.311987Z","shell.execute_reply":"2022-11-03T17:53:34.325132Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             filename    class\n0  fearful/im3787.png  fearful\n1  fearful/im3371.png  fearful\n2  fearful/im3169.png  fearful\n3   fearful/im361.png  fearful\n4   fearful/im191.png  fearful","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fearful/im3787.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fearful/im3371.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fearful/im3169.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fearful/im361.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fearful/im191.png</td>\n      <td>fearful</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:34.328260Z","iopub.execute_input":"2022-11-03T17:53:34.328609Z","iopub.status.idle":"2022-11-03T17:53:34.337837Z","shell.execute_reply.started":"2022-11-03T17:53:34.328574Z","shell.execute_reply":"2022-11-03T17:53:34.336660Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"             filename    class\n0  fearful/im1375.png  fearful\n1  fearful/im3465.png  fearful\n2  fearful/im3209.png  fearful\n3  fearful/im1444.png  fearful\n4  fearful/im1029.png  fearful","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fearful/im1375.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fearful/im3465.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fearful/im3209.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fearful/im1444.png</td>\n      <td>fearful</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fearful/im1029.png</td>\n      <td>fearful</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n\ntrain_generator = datagen.flow_from_dataframe(dataframe = train,\n                                              directory = train_path,\n                                              class_mode='categorical',\n                                              batch_size = 32,\n                                              target_size=(224, 224),\n                                              subset='training',\n                                              validate_filenames=False)\n\nvalidation_generator = datagen.flow_from_dataframe(dataframe = train, \n                                                   directory = train_path,\n                                                   class_mode='categorical',\n                                                   batch_size = 32, \n                                                   target_size=(224, 224), \n                                                   subset='validation',\n                                                   validate_filenames=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:34.339865Z","iopub.execute_input":"2022-11-03T17:53:34.340228Z","iopub.status.idle":"2022-11-03T17:53:34.367615Z","shell.execute_reply.started":"2022-11-03T17:53:34.340193Z","shell.execute_reply":"2022-11-03T17:53:34.366585Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 1798 non-validated image filenames belonging to 7 classes.\nFound 449 non-validated image filenames belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## VGG16","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nfrom keras.applications.vgg16 import VGG16\n\nimage_size = 224\n\nweight_path = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nvgg16_base_model = VGG16(weights=weight_path, \n                         include_top=False, \n                         input_shape=(image_size, image_size, 3))\n\nfor layer in vgg16_base_model.layers:\n    layer.trainable = False\n\nvgg16_pretrained_model = tf.keras.Sequential([\n    vgg16_base_model,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(7, activation='softmax')\n])\nvgg16_pretrained_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nvgg16_pretrained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:34.369221Z","iopub.execute_input":"2022-11-03T17:53:34.369613Z","iopub.status.idle":"2022-11-03T17:53:38.131787Z","shell.execute_reply.started":"2022-11-03T17:53:34.369561Z","shell.execute_reply":"2022-11-03T17:53:38.130722Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2022-11-03 17:53:34.478337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.479301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.489784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.490719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.491815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.492811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.494161: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-03 17:53:34.720983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.721868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.722604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.723295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.723977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:34.724645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.220599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.222507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.223597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.224671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.225705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.226645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-03 17:53:36.227150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-03 17:53:36.228131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Functional)           (None, 7, 7, 512)         14714688  \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               6422784   \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 1799      \n=================================================================\nTotal params: 21,139,271\nTrainable params: 6,424,583\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\nhistory_vgg16 = vgg16_pretrained_model.fit(train_generator, epochs=10, callbacks=callback)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:53:38.133267Z","iopub.execute_input":"2022-11-03T17:53:38.133886Z","iopub.status.idle":"2022-11-03T17:55:02.610784Z","shell.execute_reply.started":"2022-11-03T17:53:38.133846Z","shell.execute_reply":"2022-11-03T17:55:02.609612Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2022-11-03 17:53:38.268576: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-11-03 17:53:39.514368: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"57/57 [==============================] - 18s 155ms/step - loss: 2.2970 - accuracy: 0.3092\nEpoch 2/10\n57/57 [==============================] - 7s 126ms/step - loss: 1.1035 - accuracy: 0.5806\nEpoch 3/10\n57/57 [==============================] - 7s 125ms/step - loss: 0.8340 - accuracy: 0.6991\nEpoch 4/10\n57/57 [==============================] - 7s 122ms/step - loss: 0.6803 - accuracy: 0.7675\nEpoch 5/10\n57/57 [==============================] - 7s 121ms/step - loss: 0.4667 - accuracy: 0.8643\nEpoch 6/10\n57/57 [==============================] - 7s 120ms/step - loss: 0.3638 - accuracy: 0.9093\nEpoch 7/10\n57/57 [==============================] - 7s 120ms/step - loss: 0.3498 - accuracy: 0.8888\nEpoch 8/10\n57/57 [==============================] - 7s 123ms/step - loss: 0.3212 - accuracy: 0.9116\nEpoch 9/10\n57/57 [==============================] - 7s 120ms/step - loss: 0.2115 - accuracy: 0.9544\nEpoch 10/10\n57/57 [==============================] - 7s 121ms/step - loss: 0.1801 - accuracy: 0.9677\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg16_pretrained_model.evaluate(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:55:02.612690Z","iopub.execute_input":"2022-11-03T17:55:02.613114Z","iopub.status.idle":"2022-11-03T17:55:05.455862Z","shell.execute_reply.started":"2022-11-03T17:55:02.613072Z","shell.execute_reply":"2022-11-03T17:55:05.454803Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"15/15 [==============================] - 3s 165ms/step - loss: 18.0122 - accuracy: 0.1960\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[18.01223373413086, 0.19599108397960663]"},"metadata":{}}]},{"cell_type":"markdown","source":"## InceptionV3","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nfrom keras.applications.inception_v3 import InceptionV3\n\nweight_path = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\ninception_base_model = InceptionV3(weights=weight_path, \n                         include_top=False, \n                         input_shape=(image_size, image_size, 3))\n\nfor layer in inception_base_model.layers:\n    layer.trainable = False\n\ninception_pretrained_model = tf.keras.Sequential([\n    inception_base_model,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(7, activation='softmax')\n])\ninception_pretrained_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ninception_pretrained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:55:05.459493Z","iopub.execute_input":"2022-11-03T17:55:05.459834Z","iopub.status.idle":"2022-11-03T17:55:09.250668Z","shell.execute_reply.started":"2022-11-03T17:55:05.459805Z","shell.execute_reply":"2022-11-03T17:55:09.249778Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n_________________________________________________________________\nflatten (Flatten)            (None, 51200)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               13107456  \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 1799      \n=================================================================\nTotal params: 34,912,039\nTrainable params: 13,109,255\nNon-trainable params: 21,802,784\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history_inception = inception_pretrained_model.fit(train_generator, epochs=10, callbacks=callback)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:55:09.251983Z","iopub.execute_input":"2022-11-03T17:55:09.252839Z","iopub.status.idle":"2022-11-03T17:56:01.529476Z","shell.execute_reply.started":"2022-11-03T17:55:09.252800Z","shell.execute_reply":"2022-11-03T17:56:01.528534Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/10\n57/57 [==============================] - 11s 90ms/step - loss: 12.8948 - accuracy: 0.2881\nEpoch 2/10\n57/57 [==============================] - 5s 81ms/step - loss: 1.7410 - accuracy: 0.6151\nEpoch 3/10\n57/57 [==============================] - 4s 76ms/step - loss: 0.6484 - accuracy: 0.7903\nEpoch 4/10\n57/57 [==============================] - 4s 77ms/step - loss: 0.3422 - accuracy: 0.8776\nEpoch 5/10\n57/57 [==============================] - 5s 81ms/step - loss: 0.2298 - accuracy: 0.9160\nEpoch 6/10\n57/57 [==============================] - 5s 84ms/step - loss: 0.0740 - accuracy: 0.9822\nEpoch 7/10\n57/57 [==============================] - 5s 80ms/step - loss: 0.0271 - accuracy: 0.9983\nEpoch 8/10\n57/57 [==============================] - 4s 76ms/step - loss: 0.0156 - accuracy: 1.0000\nEpoch 9/10\n57/57 [==============================] - 4s 76ms/step - loss: 0.0088 - accuracy: 1.0000\nEpoch 10/10\n57/57 [==============================] - 4s 75ms/step - loss: 0.0070 - accuracy: 1.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"inception_pretrained_model.evaluate(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:56:01.534543Z","iopub.execute_input":"2022-11-03T17:56:01.534883Z","iopub.status.idle":"2022-11-03T17:56:04.515155Z","shell.execute_reply.started":"2022-11-03T17:56:01.534846Z","shell.execute_reply":"2022-11-03T17:56:04.513769Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"15/15 [==============================] - 3s 114ms/step - loss: 58.4265 - accuracy: 0.1314\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[58.426544189453125, 0.1314031183719635]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Xception","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nfrom keras.applications.xception import Xception\n\nweight_path = '../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\nxception_base_model = Xception(weights=weight_path, \n                         include_top=False, \n                         input_shape=(image_size, image_size, 3))\n\nfor layer in xception_base_model.layers:\n    layer.trainable = False\n\nxception_pretrained_model = tf.keras.Sequential([\n    xception_base_model,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(7, activation='softmax')\n])\nxception_pretrained_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nxception_pretrained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:56:04.516814Z","iopub.execute_input":"2022-11-03T17:56:04.517219Z","iopub.status.idle":"2022-11-03T17:56:07.142774Z","shell.execute_reply.started":"2022-11-03T17:56:04.517178Z","shell.execute_reply":"2022-11-03T17:56:07.141720Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nxception (Functional)        (None, 7, 7, 2048)        20861480  \n_________________________________________________________________\nflatten (Flatten)            (None, 100352)            0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               25690368  \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 1799      \n=================================================================\nTotal params: 46,553,647\nTrainable params: 25,692,167\nNon-trainable params: 20,861,480\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history_inception_xception = xception_pretrained_model.fit(train_generator, epochs=10, callbacks=callback)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:56:07.144503Z","iopub.execute_input":"2022-11-03T17:56:07.144877Z","iopub.status.idle":"2022-11-03T17:57:27.643510Z","shell.execute_reply.started":"2022-11-03T17:56:07.144842Z","shell.execute_reply":"2022-11-03T17:57:27.642574Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/10\n57/57 [==============================] - 11s 138ms/step - loss: 7.7750 - accuracy: 0.2920\nEpoch 2/10\n57/57 [==============================] - 7s 128ms/step - loss: 1.1369 - accuracy: 0.5962\nEpoch 3/10\n57/57 [==============================] - 7s 130ms/step - loss: 0.6353 - accuracy: 0.7697\nEpoch 4/10\n57/57 [==============================] - 8s 132ms/step - loss: 0.4390 - accuracy: 0.8548\nEpoch 5/10\n57/57 [==============================] - 8s 132ms/step - loss: 0.2651 - accuracy: 0.9232\nEpoch 6/10\n57/57 [==============================] - 8s 131ms/step - loss: 0.1925 - accuracy: 0.9538\nEpoch 7/10\n57/57 [==============================] - 8s 131ms/step - loss: 0.1149 - accuracy: 0.9883\nEpoch 8/10\n57/57 [==============================] - 8s 133ms/step - loss: 0.0775 - accuracy: 0.9933\nEpoch 9/10\n57/57 [==============================] - 8s 133ms/step - loss: 0.0527 - accuracy: 0.9983\nEpoch 10/10\n57/57 [==============================] - 7s 129ms/step - loss: 0.0356 - accuracy: 1.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"xception_pretrained_model.evaluate(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-11-03T17:57:27.645396Z","iopub.execute_input":"2022-11-03T17:57:27.645812Z","iopub.status.idle":"2022-11-03T17:57:30.960769Z","shell.execute_reply.started":"2022-11-03T17:57:27.645772Z","shell.execute_reply":"2022-11-03T17:57:30.959775Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"15/15 [==============================] - 3s 147ms/step - loss: 23.4791 - accuracy: 0.1292\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[23.47905158996582, 0.12917594611644745]"},"metadata":{}}]},{"cell_type":"markdown","source":"* Out of the 3 models, VGG16 performs the best on the validation data. \n* Minimum loss of 18.01 and maximum accuracy of 19.59%.","metadata":{}}]}