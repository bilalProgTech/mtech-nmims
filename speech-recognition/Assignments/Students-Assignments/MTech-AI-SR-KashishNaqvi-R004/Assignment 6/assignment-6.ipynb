{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:33.020032Z",
     "iopub.status.busy": "2022-09-23T01:56:33.019280Z",
     "iopub.status.idle": "2022-09-23T01:56:39.299753Z",
     "shell.execute_reply": "2022-09-23T01:56:39.298522Z",
     "shell.execute_reply.started": "2022-09-23T01:56:33.019942Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Input, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib_venn import venn2\n",
    "import seaborn as sns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:59:40.522383Z",
     "iopub.status.busy": "2022-09-23T01:59:40.521996Z",
     "iopub.status.idle": "2022-09-23T01:59:40.602246Z",
     "shell.execute_reply": "2022-09-23T01:59:40.601186Z",
     "shell.execute_reply.started": "2022-09-23T01:59:40.522351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_or_train dialect_region speaker_id       filename  \\\n",
       "0    1.0         TRAIN            DR4      MMDM0  SI681.WAV.wav   \n",
       "1    2.0         TRAIN            DR4      MMDM0     SI1311.PHN   \n",
       "2    3.0         TRAIN            DR4      MMDM0     SI1311.WRD   \n",
       "3    4.0         TRAIN            DR4      MMDM0      SX321.PHN   \n",
       "4    5.0         TRAIN            DR4      MMDM0      SX321.WRD   \n",
       "\n",
       "              path_from_data_dir        path_from_data_dir_windows  \\\n",
       "0  TRAIN/DR4/MMDM0/SI681.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "1     TRAIN/DR4/MMDM0/SI1311.PHN     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "2     TRAIN/DR4/MMDM0/SI1311.WRD     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "3      TRAIN/DR4/MMDM0/SX321.PHN      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "4      TRAIN/DR4/MMDM0/SX321.WRD      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "\n",
       "  is_converted_audio is_audio is_word_file is_phonetic_file is_sentence_file  \n",
       "0               True     True        False            False            False  \n",
       "1              False    False        False             True            False  \n",
       "2              False    False         True            False            False  \n",
       "3              False    False        False             True            False  \n",
       "4              False    False         True            False            False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/darpa-timit-acousticphonetic-continuous-speech/train_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:59:56.754900Z",
     "iopub.status.busy": "2022-09-23T01:59:56.754431Z",
     "iopub.status.idle": "2022-09-23T01:59:56.797193Z",
     "shell.execute_reply": "2022-09-23T01:59:56.796324Z",
     "shell.execute_reply.started": "2022-09-23T01:59:56.754860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31678 entries, 0 to 31677\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   index                       23100 non-null  float64\n",
      " 1   test_or_train               23100 non-null  object \n",
      " 2   dialect_region              23100 non-null  object \n",
      " 3   speaker_id                  23100 non-null  object \n",
      " 4   filename                    23100 non-null  object \n",
      " 5   path_from_data_dir          23100 non-null  object \n",
      " 6   path_from_data_dir_windows  23100 non-null  object \n",
      " 7   is_converted_audio          23100 non-null  object \n",
      " 8   is_audio                    23100 non-null  object \n",
      " 9   is_word_file                23100 non-null  object \n",
      " 10  is_phonetic_file            8400 non-null   object \n",
      " 11  is_sentence_file            23100 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:39.486172Z",
     "iopub.status.busy": "2022-09-23T01:56:39.485819Z",
     "iopub.status.idle": "2022-09-23T01:56:39.536424Z",
     "shell.execute_reply": "2022-09-23T01:56:39.534590Z",
     "shell.execute_reply.started": "2022-09-23T01:56:39.486131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>3404.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX111.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX111.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX111.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>3409.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SI873.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SI873.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SI873.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>3413.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SI2271.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SI2271.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SI2271.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>3414.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX201.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX201.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX201.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>3416.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SA1.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SA1.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SA1.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id    filename  \\\n",
       "3403  3404.0         TRAIN            DR3      MDNS0   SX111.TXT   \n",
       "3408  3409.0         TRAIN            DR3      MDNS0   SI873.TXT   \n",
       "3412  3413.0         TRAIN            DR3      MDNS0  SI2271.TXT   \n",
       "3413  3414.0         TRAIN            DR3      MDNS0   SX201.TXT   \n",
       "3415  3416.0         TRAIN            DR3      MDNS0     SA1.TXT   \n",
       "\n",
       "              path_from_data_dir     path_from_data_dir_windows  \\\n",
       "3403   TRAIN/DR3/MDNS0/SX111.TXT   TRAIN\\\\DR3\\\\MDNS0\\\\SX111.TXT   \n",
       "3408   TRAIN/DR3/MDNS0/SI873.TXT   TRAIN\\\\DR3\\\\MDNS0\\\\SI873.TXT   \n",
       "3412  TRAIN/DR3/MDNS0/SI2271.TXT  TRAIN\\\\DR3\\\\MDNS0\\\\SI2271.TXT   \n",
       "3413   TRAIN/DR3/MDNS0/SX201.TXT   TRAIN\\\\DR3\\\\MDNS0\\\\SX201.TXT   \n",
       "3415     TRAIN/DR3/MDNS0/SA1.TXT     TRAIN\\\\DR3\\\\MDNS0\\\\SA1.TXT   \n",
       "\n",
       "     is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "3403              False    False        False            False   \n",
       "3408              False    False        False            False   \n",
       "3412              False    False        False            False   \n",
       "3413              False    False        False            False   \n",
       "3415              False    False        False            False   \n",
       "\n",
       "     is_sentence_file  \n",
       "3403             True  \n",
       "3408             True  \n",
       "3412             True  \n",
       "3413             True  \n",
       "3415             True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Selecting only txt files\n",
    "data_txt = data[(data[\"is_sentence_file\"] == True) & (data[\"dialect_region\"].isin([\"DR1\",\"DR2\",\"DR3\"]))]\n",
    "data_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Use DR1 and DR2 dialect for training the model and DR3 dialect for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:00:16.847846Z",
     "iopub.status.busy": "2022-09-23T02:00:16.847144Z",
     "iopub.status.idle": "2022-09-23T02:00:16.858531Z",
     "shell.execute_reply": "2022-09-23T02:00:16.857312Z",
     "shell.execute_reply.started": "2022-09-23T02:00:16.847809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DR7    3850\n",
       "DR3    3800\n",
       "DR2    3800\n",
       "DR5    3500\n",
       "DR4    3400\n",
       "DR1    1900\n",
       "DR6    1750\n",
       "DR8    1100\n",
       "Name: dialect_region, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dialect_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:01:00.927338Z",
     "iopub.status.busy": "2022-09-23T02:01:00.926751Z",
     "iopub.status.idle": "2022-09-23T02:01:00.937410Z",
     "shell.execute_reply": "2022-09-23T02:01:00.936496Z",
     "shell.execute_reply.started": "2022-09-23T02:01:00.927302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DR7    3850\n",
       "DR3    3800\n",
       "DR2    3800\n",
       "DR5    3500\n",
       "DR4    3400\n",
       "DR1    1900\n",
       "DR6    1750\n",
       "DR8    1100\n",
       "Name: dialect_region, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dialect_region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:01:47.718325Z",
     "iopub.status.busy": "2022-09-23T02:01:47.717873Z",
     "iopub.status.idle": "2022-09-23T02:01:47.761566Z",
     "shell.execute_reply": "2022-09-23T02:01:47.760661Z",
     "shell.execute_reply.started": "2022-09-23T02:01:47.718287Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df[\"dialect_region\"] != 'DR4']\n",
    "df = df[df[\"dialect_region\"] != 'DR5']\n",
    "df = df[df[\"dialect_region\"] != 'DR6']\n",
    "df = df[df[\"dialect_region\"] != 'DR7']\n",
    "df = df[df[\"dialect_region\"] != 'DR8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:01:50.982918Z",
     "iopub.status.busy": "2022-09-23T02:01:50.982233Z",
     "iopub.status.idle": "2022-09-23T02:01:50.999153Z",
     "shell.execute_reply": "2022-09-23T02:01:50.998081Z",
     "shell.execute_reply.started": "2022-09-23T02:01:50.982881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                          8578\n",
       "test_or_train                  8578\n",
       "dialect_region                 8578\n",
       "speaker_id                     8578\n",
       "filename                       8578\n",
       "path_from_data_dir             8578\n",
       "path_from_data_dir_windows     8578\n",
       "is_converted_audio             8578\n",
       "is_audio                       8578\n",
       "is_word_file                   8578\n",
       "is_phonetic_file              13078\n",
       "is_sentence_file               8578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:01:54.492930Z",
     "iopub.status.busy": "2022-09-23T02:01:54.492511Z",
     "iopub.status.idle": "2022-09-23T02:01:54.518545Z",
     "shell.execute_reply": "2022-09-23T02:01:54.517630Z",
     "shell.execute_reply.started": "2022-09-23T02:01:54.492897Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:02:15.092206Z",
     "iopub.status.busy": "2022-09-23T02:02:15.091719Z",
     "iopub.status.idle": "2022-09-23T02:02:15.115206Z",
     "shell.execute_reply": "2022-09-23T02:02:15.114139Z",
     "shell.execute_reply.started": "2022-09-23T02:02:15.092166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                         0\n",
       "test_or_train                 0\n",
       "dialect_region                0\n",
       "speaker_id                    0\n",
       "filename                      0\n",
       "path_from_data_dir            0\n",
       "path_from_data_dir_windows    0\n",
       "is_converted_audio            0\n",
       "is_audio                      0\n",
       "is_word_file                  0\n",
       "is_phonetic_file              0\n",
       "is_sentence_file              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:02:27.528308Z",
     "iopub.status.busy": "2022-09-23T02:02:27.527941Z",
     "iopub.status.idle": "2022-09-23T02:02:27.538750Z",
     "shell.execute_reply": "2022-09-23T02:02:27.537701Z",
     "shell.execute_reply.started": "2022-09-23T02:02:27.528277Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"File_ext\"]=df[\"path_from_data_dir\"].str.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:02:36.217509Z",
     "iopub.status.busy": "2022-09-23T02:02:36.217131Z",
     "iopub.status.idle": "2022-09-23T02:02:36.221914Z",
     "shell.execute_reply": "2022-09-23T02:02:36.220799Z",
     "shell.execute_reply.started": "2022-09-23T02:02:36.217461Z"
    }
   },
   "outputs": [],
   "source": [
    "def File_extention(x):\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:02:44.299626Z",
     "iopub.status.busy": "2022-09-23T02:02:44.299256Z",
     "iopub.status.idle": "2022-09-23T02:02:44.322622Z",
     "shell.execute_reply": "2022-09-23T02:02:44.321650Z",
     "shell.execute_reply.started": "2022-09-23T02:02:44.299594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "      <th>File_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>3401.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX291.WRD</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX291.WRD</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX291.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[TRAIN/DR3/MDNS0/SX291, WRD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>3402.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX111.WAV</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX111.WAV</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX111.WAV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[TRAIN/DR3/MDNS0/SX111, WAV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>3403.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX291.PHN</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX291.PHN</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX291.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[TRAIN/DR3/MDNS0/SX291, PHN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>3404.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX111.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX111.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX111.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[TRAIN/DR3/MDNS0/SX111, TXT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>3405.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX21.WRD</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX21.WRD</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX21.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[TRAIN/DR3/MDNS0/SX21, WRD]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id   filename  \\\n",
       "3400  3401.0         TRAIN            DR3      MDNS0  SX291.WRD   \n",
       "3401  3402.0         TRAIN            DR3      MDNS0  SX111.WAV   \n",
       "3402  3403.0         TRAIN            DR3      MDNS0  SX291.PHN   \n",
       "3403  3404.0         TRAIN            DR3      MDNS0  SX111.TXT   \n",
       "3404  3405.0         TRAIN            DR3      MDNS0   SX21.WRD   \n",
       "\n",
       "             path_from_data_dir    path_from_data_dir_windows  \\\n",
       "3400  TRAIN/DR3/MDNS0/SX291.WRD  TRAIN\\\\DR3\\\\MDNS0\\\\SX291.WRD   \n",
       "3401  TRAIN/DR3/MDNS0/SX111.WAV  TRAIN\\\\DR3\\\\MDNS0\\\\SX111.WAV   \n",
       "3402  TRAIN/DR3/MDNS0/SX291.PHN  TRAIN\\\\DR3\\\\MDNS0\\\\SX291.PHN   \n",
       "3403  TRAIN/DR3/MDNS0/SX111.TXT  TRAIN\\\\DR3\\\\MDNS0\\\\SX111.TXT   \n",
       "3404   TRAIN/DR3/MDNS0/SX21.WRD   TRAIN\\\\DR3\\\\MDNS0\\\\SX21.WRD   \n",
       "\n",
       "     is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "3400              False    False         True            False   \n",
       "3401              False     True        False            False   \n",
       "3402              False    False        False             True   \n",
       "3403              False    False        False            False   \n",
       "3404              False    False         True            False   \n",
       "\n",
       "     is_sentence_file                      File_ext  \n",
       "3400            False  [TRAIN/DR3/MDNS0/SX291, WRD]  \n",
       "3401            False  [TRAIN/DR3/MDNS0/SX111, WAV]  \n",
       "3402            False  [TRAIN/DR3/MDNS0/SX291, PHN]  \n",
       "3403             True  [TRAIN/DR3/MDNS0/SX111, TXT]  \n",
       "3404            False   [TRAIN/DR3/MDNS0/SX21, WRD]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:02:56.893239Z",
     "iopub.status.busy": "2022-09-23T02:02:56.892825Z",
     "iopub.status.idle": "2022-09-23T02:02:56.905239Z",
     "shell.execute_reply": "2022-09-23T02:02:56.904210Z",
     "shell.execute_reply.started": "2022-09-23T02:02:56.893207Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"File_ext\"]=df[\"File_ext\"].apply(lambda x:File_extention(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:03:09.527682Z",
     "iopub.status.busy": "2022-09-23T02:03:09.527305Z",
     "iopub.status.idle": "2022-09-23T02:03:09.537065Z",
     "shell.execute_reply": "2022-09-23T02:03:09.536096Z",
     "shell.execute_reply.started": "2022-09-23T02:03:09.527649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400    WRD\n",
       "3401    WAV\n",
       "3402    PHN\n",
       "3403    TXT\n",
       "3404    WRD\n",
       "       ... \n",
       "8395    WAV\n",
       "8396    WAV\n",
       "8397    WAV\n",
       "8398    TXT\n",
       "8399    WAV\n",
       "Name: File_ext, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"File_ext\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Pick only .PHN, .WRD and .TXT files for each specified dialect distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:03:32.793521Z",
     "iopub.status.busy": "2022-09-23T02:03:32.793131Z",
     "iopub.status.idle": "2022-09-23T02:03:32.802589Z",
     "shell.execute_reply": "2022-09-23T02:03:32.801477Z",
     "shell.execute_reply.started": "2022-09-23T02:03:32.793468Z"
    }
   },
   "outputs": [],
   "source": [
    "files=[\"PHN\",\"WRD\",\"TXT\"]\n",
    "df=df.loc[df['File_ext'].isin(files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:03:52.547987Z",
     "iopub.status.busy": "2022-09-23T02:03:52.547634Z",
     "iopub.status.idle": "2022-09-23T02:03:52.566416Z",
     "shell.execute_reply": "2022-09-23T02:03:52.565211Z",
     "shell.execute_reply.started": "2022-09-23T02:03:52.547958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "      <th>File_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>3401.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX291.WRD</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX291.WRD</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX291.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>3403.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX291.PHN</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX291.PHN</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX291.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>3404.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX111.TXT</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX111.TXT</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX111.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>TXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>3405.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX21.WRD</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX21.WRD</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX21.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>3407.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>SX21.PHN</td>\n",
       "      <td>TRAIN/DR3/MDNS0/SX21.PHN</td>\n",
       "      <td>TRAIN\\\\DR3\\\\MDNS0\\\\SX21.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PHN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id   filename  \\\n",
       "3400  3401.0         TRAIN            DR3      MDNS0  SX291.WRD   \n",
       "3402  3403.0         TRAIN            DR3      MDNS0  SX291.PHN   \n",
       "3403  3404.0         TRAIN            DR3      MDNS0  SX111.TXT   \n",
       "3404  3405.0         TRAIN            DR3      MDNS0   SX21.WRD   \n",
       "3406  3407.0         TRAIN            DR3      MDNS0   SX21.PHN   \n",
       "\n",
       "             path_from_data_dir    path_from_data_dir_windows  \\\n",
       "3400  TRAIN/DR3/MDNS0/SX291.WRD  TRAIN\\\\DR3\\\\MDNS0\\\\SX291.WRD   \n",
       "3402  TRAIN/DR3/MDNS0/SX291.PHN  TRAIN\\\\DR3\\\\MDNS0\\\\SX291.PHN   \n",
       "3403  TRAIN/DR3/MDNS0/SX111.TXT  TRAIN\\\\DR3\\\\MDNS0\\\\SX111.TXT   \n",
       "3404   TRAIN/DR3/MDNS0/SX21.WRD   TRAIN\\\\DR3\\\\MDNS0\\\\SX21.WRD   \n",
       "3406   TRAIN/DR3/MDNS0/SX21.PHN   TRAIN\\\\DR3\\\\MDNS0\\\\SX21.PHN   \n",
       "\n",
       "     is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "3400              False    False         True            False   \n",
       "3402              False    False        False             True   \n",
       "3403              False    False        False            False   \n",
       "3404              False    False         True            False   \n",
       "3406              False    False        False             True   \n",
       "\n",
       "     is_sentence_file File_ext  \n",
       "3400            False      WRD  \n",
       "3402            False      PHN  \n",
       "3403             True      TXT  \n",
       "3404            False      WRD  \n",
       "3406            False      PHN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:05:27.911632Z",
     "iopub.status.busy": "2022-09-23T02:05:27.911247Z",
     "iopub.status.idle": "2022-09-23T02:05:27.922954Z",
     "shell.execute_reply": "2022-09-23T02:05:27.921773Z",
     "shell.execute_reply.started": "2022-09-23T02:05:27.911600Z"
    }
   },
   "outputs": [],
   "source": [
    "dff[\"Phoneme\"] = ''\n",
    "dff[\"Phoneme\"] = dff[\"path_from_data_dir\"].apply(lambda x: add_phn(x))\n",
    "dff[\"Word\"] = \"\"\n",
    "dff[\"Word\"] = dff[\"path_from_data_dir\"].apply(lambda x: add_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:06:23.869440Z",
     "iopub.status.busy": "2022-09-23T02:06:23.868356Z",
     "iopub.status.idle": "2022-09-23T02:06:23.879491Z",
     "shell.execute_reply": "2022-09-23T02:06:23.878460Z",
     "shell.execute_reply.started": "2022-09-23T02:06:23.869401Z"
    }
   },
   "outputs": [],
   "source": [
    "dff.columns = [\"index\",\"test_or_train\",\"dialect_region\",\"speaker_id\",\n",
    "                    \"Text\",\"Phoneme\",\"Word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:39.579131Z",
     "iopub.status.busy": "2022-09-23T01:56:39.578544Z",
     "iopub.status.idle": "2022-09-23T01:56:39.600567Z",
     "shell.execute_reply": "2022-09-23T01:56:39.599695Z",
     "shell.execute_reply.started": "2022-09-23T01:56:39.579098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>3404.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>3409.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>3413.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>3414.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>3416.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR3</td>\n",
       "      <td>MDNS0</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "      <td>../input/darpa-timit-acousticphonetic-continuo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id  \\\n",
       "3403  3404.0         TRAIN            DR3      MDNS0   \n",
       "3408  3409.0         TRAIN            DR3      MDNS0   \n",
       "3412  3413.0         TRAIN            DR3      MDNS0   \n",
       "3413  3414.0         TRAIN            DR3      MDNS0   \n",
       "3415  3416.0         TRAIN            DR3      MDNS0   \n",
       "\n",
       "                                                   Text  \\\n",
       "3403  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3408  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3412  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3413  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3415  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "\n",
       "                                                Phoneme  \\\n",
       "3403  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3408  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3412  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3413  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "3415  ../input/darpa-timit-acousticphonetic-continuo...   \n",
       "\n",
       "                                                   Word  \n",
       "3403  ../input/darpa-timit-acousticphonetic-continuo...  \n",
       "3408  ../input/darpa-timit-acousticphonetic-continuo...  \n",
       "3412  ../input/darpa-timit-acousticphonetic-continuo...  \n",
       "3413  ../input/darpa-timit-acousticphonetic-continuo...  \n",
       "3415  ../input/darpa-timit-acousticphonetic-continuo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff[\"Text\"] = \"../input/darpa-timit-acousticphonetic-continuous-speech/data/\"+dff[\"Text\"]\n",
    "dff[\"Phoneme\"] = \"../input/darpa-timit-acousticphonetic-continuous-speech/data/\"+dff[\"Phoneme\"]\n",
    "dff[\"Word\"] = \"../input/darpa-timit-acousticphonetic-continuous-speech/data/\"+dff[\"Word\"]\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:07:27.534841Z",
     "iopub.status.busy": "2022-09-23T02:07:27.534433Z",
     "iopub.status.idle": "2022-09-23T02:07:27.541347Z",
     "shell.execute_reply": "2022-09-23T02:07:27.540208Z",
     "shell.execute_reply.started": "2022-09-23T02:07:27.534809Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train= dff[dff[\"dialect_region\"] != 'DR3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:07:36.577316Z",
     "iopub.status.busy": "2022-09-23T02:07:36.576955Z",
     "iopub.status.idle": "2022-09-23T02:07:36.585175Z",
     "shell.execute_reply": "2022-09-23T02:07:36.584120Z",
     "shell.execute_reply.started": "2022-09-23T02:07:36.577286Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test= dff[dff[\"dialect_region\"] != 'DR1']\n",
    "df_test= df_test[df_test[\"dialect_region\"] != 'DR2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:07:47.651055Z",
     "iopub.status.busy": "2022-09-23T02:07:47.650439Z",
     "iopub.status.idle": "2022-09-23T02:07:47.665880Z",
     "shell.execute_reply": "2022-09-23T02:07:47.664860Z",
     "shell.execute_reply.started": "2022-09-23T02:07:47.651020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7200</th>\n",
       "      <td>7201.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>FJKL0</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX32.PHN</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX32.PHN</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX32.WRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>FJKL0</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX32.WRD</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX32.PHN</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX32.WRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>7204.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>FJKL0</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SI932.WRD</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SI932.PHN</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SI932.WRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>7205.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>FJKL0</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX302.TXT</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX302.PHN</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX302.WRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>7206.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>FJKL0</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX122.WRD</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX122.PHN</td>\n",
       "      <td>TRAIN/DR2/FJKL0/SX122.WRD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id  \\\n",
       "7200  7201.0         TRAIN            DR2      FJKL0   \n",
       "7202  7203.0         TRAIN            DR2      FJKL0   \n",
       "7203  7204.0         TRAIN            DR2      FJKL0   \n",
       "7204  7205.0         TRAIN            DR2      FJKL0   \n",
       "7205  7206.0         TRAIN            DR2      FJKL0   \n",
       "\n",
       "                           Text                    Phoneme  \\\n",
       "7200   TRAIN/DR2/FJKL0/SX32.PHN   TRAIN/DR2/FJKL0/SX32.PHN   \n",
       "7202   TRAIN/DR2/FJKL0/SX32.WRD   TRAIN/DR2/FJKL0/SX32.PHN   \n",
       "7203  TRAIN/DR2/FJKL0/SI932.WRD  TRAIN/DR2/FJKL0/SI932.PHN   \n",
       "7204  TRAIN/DR2/FJKL0/SX302.TXT  TRAIN/DR2/FJKL0/SX302.PHN   \n",
       "7205  TRAIN/DR2/FJKL0/SX122.WRD  TRAIN/DR2/FJKL0/SX122.PHN   \n",
       "\n",
       "                           Word  \n",
       "7200   TRAIN/DR2/FJKL0/SX32.WRD  \n",
       "7202   TRAIN/DR2/FJKL0/SX32.WRD  \n",
       "7203  TRAIN/DR2/FJKL0/SI932.WRD  \n",
       "7204  TRAIN/DR2/FJKL0/SX302.WRD  \n",
       "7205  TRAIN/DR2/FJKL0/SX122.WRD  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:39.602383Z",
     "iopub.status.busy": "2022-09-23T01:56:39.601838Z",
     "iopub.status.idle": "2022-09-23T01:56:39.609776Z",
     "shell.execute_reply": "2022-09-23T01:56:39.608761Z",
     "shell.execute_reply.started": "2022-09-23T01:56:39.602348Z"
    }
   },
   "outputs": [],
   "source": [
    "Train = data_txt[(data_txt[\"dialect_region\"] == \"DR1\")|\n",
    "            (data_txt[\"dialect_region\"] == \"DR2\")]\n",
    "Test = data_txt[data_txt[\"dialect_region\"] == \"DR3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:08:10.408197Z",
     "iopub.status.busy": "2022-09-23T02:08:10.407843Z",
     "iopub.status.idle": "2022-09-23T02:08:10.416398Z",
     "shell.execute_reply": "2022-09-23T02:08:10.415339Z",
     "shell.execute_reply.started": "2022-09-23T02:08:10.408167Z"
    }
   },
   "outputs": [],
   "source": [
    "def words(dir):\n",
    "  w=[]\n",
    "  phn = []\n",
    "  dir=dir.split('.')[0]\n",
    "  dict_file_wrd = open(str(dir+\".WRD\"), 'r')\n",
    "  dict_file_phn = open(str(dir+\".PHN\"), 'r')\n",
    "  with dict_file_wrd as f:\n",
    "    phonics = [line.rstrip('\\n') for line in f]\n",
    "    for p in phonics:\n",
    "      p=p.split(' ')\n",
    "      s=\"\".join(p[2:])\n",
    "      w.append(s)\n",
    "  with dict_file_phn as f:\n",
    "    phonics = [line.rstrip('\\n') for line in f]\n",
    "    for p in phonics:\n",
    "      p=p.split(' ')\n",
    "      s=\"\".join(p[2:])\n",
    "      phn.append(s)\n",
    "  return w,phn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.193079Z",
     "iopub.status.busy": "2022-09-23T01:56:50.192698Z",
     "iopub.status.idle": "2022-09-23T01:56:50.204007Z",
     "shell.execute_reply": "2022-09-23T01:56:50.202907Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.193038Z"
    }
   },
   "outputs": [],
   "source": [
    "train_vocab = {}\n",
    "test_vocab = {}\n",
    "for word,phoneme in zip(train_w,train_p):\n",
    "    train_vocab[word] = phoneme\n",
    "for word,phoneme in zip(test_w,test_p):\n",
    "    test_vocab[word] = phoneme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a vocabulary for each word with its associated phonemes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.206313Z",
     "iopub.status.busy": "2022-09-23T01:56:50.205739Z",
     "iopub.status.idle": "2022-09-23T01:56:50.213883Z",
     "shell.execute_reply": "2022-09-23T01:56:50.212613Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.206273Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = {**train_vocab,**test_vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.227867Z",
     "iopub.status.busy": "2022-09-23T01:56:50.227457Z",
     "iopub.status.idle": "2022-09-23T01:56:50.237464Z",
     "shell.execute_reply": "2022-09-23T01:56:50.236577Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.227778Z"
    }
   },
   "outputs": [],
   "source": [
    "Train_vocab = pd.DataFrame({\"Word\":train_vocab.keys(),\"Phoneme\":train_vocab.values()})\n",
    "Test_vocab = pd.DataFrame({\"Word\":test_vocab.keys(),\"Phoneme\":test_vocab.values()})\n",
    "Vocab = pd.DataFrame({\"Word\":vocab.keys(),\"Phoneme\":vocab.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.239761Z",
     "iopub.status.busy": "2022-09-23T01:56:50.239245Z",
     "iopub.status.idle": "2022-09-23T01:56:50.253335Z",
     "shell.execute_reply": "2022-09-23T01:56:50.252346Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.239725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tofu</td>\n",
       "      <td>t ow f uw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>ix z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>made</td>\n",
       "      <td>m ey dx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from</td>\n",
       "      <td>f axr m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>processed</td>\n",
       "      <td>pcl p r aa s eh s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>pastime</td>\n",
       "      <td>p ae s tcl t ay m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>hooking</td>\n",
       "      <td>hh uh kcl k ix ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>braiding</td>\n",
       "      <td>bcl b r ey dx iy ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>rugs</td>\n",
       "      <td>epi r ah gcl g z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>worth</td>\n",
       "      <td>w er th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3094 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word              Phoneme\n",
       "0          tofu            t ow f uw\n",
       "1            is                 ix z\n",
       "2          made              m ey dx\n",
       "3          from              f axr m\n",
       "4     processed    pcl p r aa s eh s\n",
       "...         ...                  ...\n",
       "3089    pastime    p ae s tcl t ay m\n",
       "3090    hooking    hh uh kcl k ix ng\n",
       "3091   braiding  bcl b r ey dx iy ng\n",
       "3092       rugs     epi r ah gcl g z\n",
       "3093      worth              w er th\n",
       "\n",
       "[3094 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.285705Z",
     "iopub.status.busy": "2022-09-23T01:56:50.285389Z",
     "iopub.status.idle": "2022-09-23T01:56:50.296971Z",
     "shell.execute_reply": "2022-09-23T01:56:50.296006Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.285682Z"
    }
   },
   "outputs": [],
   "source": [
    "Train_file = pd.DataFrame()\n",
    "Train_file[\"Sentence\"] = train_sentence\n",
    "Train_file[\"Phoneme\"] = train_phoneme\n",
    "\n",
    "Test_file = pd.DataFrame()\n",
    "Test_file[\"Sentence\"] = test_sentence\n",
    "Test_file[\"Phoneme\"] = test_phoneme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.320034Z",
     "iopub.status.busy": "2022-09-23T01:56:50.319427Z",
     "iopub.status.idle": "2022-09-23T01:56:50.328615Z",
     "shell.execute_reply": "2022-09-23T01:56:50.327689Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.320000Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Train_file.append(Test_file)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model with available vocabulary for phoneme to word prediction. (Use sequence modeling).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.330714Z",
     "iopub.status.busy": "2022-09-23T01:56:50.330300Z",
     "iopub.status.idle": "2022-09-23T01:56:50.384185Z",
     "shell.execute_reply": "2022-09-23T01:56:50.382426Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.330681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 's': 2, 'ix': 3, 'n': 4, 'tcl': 5, 'l': 6, 'kcl': 7, 'r': 8, 'k': 9, 'iy': 10, 'dcl': 11, 't': 12, 'ih': 13, 'm': 14, 'eh': 15, 'z': 16, 'pcl': 17, 'p': 18, 'd': 19, 'ae': 20, 'ax': 21, 'axr': 22, 'ey': 23, 'aa': 24, 'dx': 25, 'f': 26, 'b': 27, 'er': 28, 'bcl': 29, 'ay': 30, 'ah': 31, 'v': 32, 'ow': 33, 'q': 34, 'ng': 35, 'gcl': 36, 'ao': 37, 'w': 38, 'sh': 39, 'g': 40, 'el': 41, 'jh': 42, 'ux': 43, 'ch': 44, 'y': 45, 'epi': 46, 'nx': 47, 'en': 48, 'hv': 49, 'aw': 50, 'pau': 51, 'th': 52, 'uw': 53, 'hh': 54, 'dh': 55, 'oy': 56, 'uh': 57, 'h': 58, 'zh': 59, 'em': 60, 'eng': 61}\n"
     ]
    }
   ],
   "source": [
    "phoneme_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
    "phoneme_tokenizer.fit_on_texts(Vocab['Phoneme'].values)\n",
    "phoneme_index = phoneme_tokenizer.word_index\n",
    "print(phoneme_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.386257Z",
     "iopub.status.busy": "2022-09-23T01:56:50.385618Z",
     "iopub.status.idle": "2022-09-23T01:56:50.395504Z",
     "shell.execute_reply": "2022-09-23T01:56:50.394414Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.386215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_length = len(phoneme_tokenizer.word_index) + 1\n",
    "phoneme_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.397366Z",
     "iopub.status.busy": "2022-09-23T01:56:50.396830Z",
     "iopub.status.idle": "2022-09-23T01:56:50.486100Z",
     "shell.execute_reply": "2022-09-23T01:56:50.484118Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.397334Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sequences = phoneme_tokenizer.texts_to_sequences(Train_vocab['Phoneme'].values)\n",
    "test_sequences = phoneme_tokenizer.texts_to_sequences(Test_vocab['Phoneme'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.493067Z",
     "iopub.status.busy": "2022-09-23T01:56:50.492668Z",
     "iopub.status.idle": "2022-09-23T01:56:50.508044Z",
     "shell.execute_reply": "2022-09-23T01:56:50.507151Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.493027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_phoneme = len(max(train_sequences, key=len))\n",
    "longest_phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.511042Z",
     "iopub.status.busy": "2022-09-23T01:56:50.510219Z",
     "iopub.status.idle": "2022-09-23T01:56:50.539558Z",
     "shell.execute_reply": "2022-09-23T01:56:50.538641Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.511007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: tofu\n",
      " Padded:[12 33 26 43  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " phoneme:t ow f ux\n"
     ]
    }
   ],
   "source": [
    "train_padded = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=longest_phoneme, padding='post')\n",
    "test_padded = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=longest_phoneme, padding='post')\n",
    "\n",
    "print(\"Word: {}\\n Padded:{}\\n phoneme:{}\".format(Train_vocab[\"Word\"][0],train_padded[0],Train_vocab[\"Phoneme\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.545742Z",
     "iopub.status.busy": "2022-09-23T01:56:50.545125Z",
     "iopub.status.idle": "2022-09-23T01:56:50.567295Z",
     "shell.execute_reply": "2022-09-23T01:56:50.566355Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.545708Z"
    }
   },
   "outputs": [],
   "source": [
    "y = Vocab['Word'].values\n",
    "y_train = Train_vocab['Word'].values\n",
    "y_test = Test_vocab[\"Word\"].values\n",
    "                      \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T01:56:50.569107Z",
     "iopub.status.busy": "2022-09-23T01:56:50.568505Z",
     "iopub.status.idle": "2022-09-23T01:56:53.832205Z",
     "shell.execute_reply": "2022-09-23T01:56:53.831172Z",
     "shell.execute_reply.started": "2022-09-23T01:56:50.569006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 01:56:50.689092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:50.791524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:50.792742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:50.794990: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-23 01:56:50.795333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:50.796391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:50.797279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:52.998198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:52.999145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:52.999881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:56:53.000478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 17, 10)            620       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100)               24400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3094)              399126    \n",
      "=================================================================\n",
      "Total params: 437,074\n",
      "Trainable params: 437,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "tf.keras.backend.clear_session()\n",
    "model = Sequential([\n",
    "    Embedding(phoneme_length, embedding_dim, \n",
    "                              input_length=longest_phoneme),\n",
    "    Bidirectional(LSTM(50)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(Vocab['Word'].unique()), activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T17:52:22.322314Z",
     "iopub.status.busy": "2022-09-17T17:52:22.321264Z",
     "iopub.status.idle": "2022-09-17T17:54:12.442470Z",
     "shell.execute_reply": "2022-09-17T17:54:12.441256Z",
     "shell.execute_reply.started": "2022-09-17T17:52:22.322253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "75/75 [==============================] - 7s 28ms/step - loss: 8.0484\n",
      "\n",
      "Epoch 2/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 8.0239\n",
      "\n",
      "Epoch 3/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 8.0082\n",
      "\n",
      "Epoch 4/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 7.9765\n",
      "\n",
      "Epoch 5/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 7.8738\n",
      "\n",
      "Epoch 6/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 7.5782\n",
      "\n",
      "Epoch 7/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 7.0607\n",
      "\n",
      "Epoch 8/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 6.3292\n",
      "\n",
      "Epoch 9/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 5.6117\n",
      "\n",
      "Epoch 10/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 4.9979\n",
      "\n",
      "Epoch 11/50\n",
      "\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 4.4618\n",
      "\n",
      "Epoch 12/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 3.9993\n",
      "\n",
      "Epoch 13/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 3.5904\n",
      "\n",
      "Epoch 14/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 3.2427\n",
      "\n",
      "Epoch 15/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 2.9241\n",
      "\n",
      "Epoch 16/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 2.6415\n",
      "\n",
      "Epoch 17/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 2.3805\n",
      "\n",
      "Epoch 18/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 2.1258\n",
      "\n",
      "Epoch 19/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 1.9086\n",
      "\n",
      "Epoch 20/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 1.7188\n",
      "\n",
      "Epoch 21/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 1.5235\n",
      "\n",
      "Epoch 22/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 1.3703\n",
      "\n",
      "Epoch 23/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 1.2267\n",
      "\n",
      "Epoch 24/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 1.0958\n",
      "\n",
      "Epoch 25/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.9772\n",
      "\n",
      "Epoch 26/50\n",
      "\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 0.8748\n",
      "\n",
      "Epoch 27/50\n",
      "\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.7870\n",
      "\n",
      "Epoch 28/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.7048\n",
      "\n",
      "Epoch 29/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.6361\n",
      "\n",
      "Epoch 30/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.5847\n",
      "\n",
      "Epoch 31/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.5210\n",
      "\n",
      "Epoch 32/50\n",
      "\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.4856\n",
      "\n",
      "Epoch 33/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.4486\n",
      "\n",
      "Epoch 34/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.3932\n",
      "\n",
      "Epoch 35/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.3578\n",
      "\n",
      "Epoch 36/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.3269\n",
      "\n",
      "Epoch 37/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.3169\n",
      "\n",
      "Epoch 38/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.2865\n",
      "\n",
      "Epoch 39/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.2639\n",
      "\n",
      "Epoch 40/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.2473\n",
      "\n",
      "Epoch 41/50\n",
      "\n",
      "75/75 [==============================] - 3s 35ms/step - loss: 0.2237\n",
      "\n",
      "Epoch 42/50\n",
      "\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 0.2147\n",
      "\n",
      "Epoch 43/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.2056\n",
      "\n",
      "Epoch 44/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.2127\n",
      "\n",
      "Epoch 45/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1953\n",
      "\n",
      "Epoch 46/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1772\n",
      "\n",
      "Epoch 47/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1669\n",
      "\n",
      "Epoch 48/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1842\n",
      "\n",
      "Epoch 49/50\n",
      "\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 0.1681\n",
      "\n",
      "Epoch 50/50\n",
      "\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 0.1668\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded,y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a pandas dataframe containing the sentence phonemes for each file.\n",
    "## 6. Predict the words of all phonemes present in the sentence using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T17:54:12.444962Z",
     "iopub.status.busy": "2022-09-17T17:54:12.444580Z",
     "iopub.status.idle": "2022-09-17T17:54:12.455048Z",
     "shell.execute_reply": "2022-09-17T17:54:12.453913Z",
     "shell.execute_reply.started": "2022-09-17T17:54:12.444927Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_words(sentence):\n",
    "    phonemes = sentence.split(\"  \")\n",
    "    #print(phonemes)\n",
    "    word_sentence = \"\"\n",
    "    for x in phonemes:\n",
    "        text_seq = phoneme_tokenizer.texts_to_sequences([x])\n",
    "        text_padded = pad_sequences(text_seq, maxlen=longest_phoneme, padding='post')\n",
    "        pred = model.predict(text_padded)\n",
    "        pred = np.argmax(pred,axis=1)\n",
    "        word = encoder.classes_[pred[0]]\n",
    "        #print(word)\n",
    "        word_sentence = word_sentence + word + \" \"\n",
    "    word_sentence = word_sentence.strip()\n",
    "    return word_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T17:54:13.665776Z",
     "iopub.status.busy": "2022-09-17T17:54:13.665438Z",
     "iopub.status.idle": "2022-09-17T18:10:20.170819Z",
     "shell.execute_reply": "2022-09-17T18:10:20.169607Z",
     "shell.execute_reply.started": "2022-09-17T17:54:13.665747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>split</th>\n",
       "      <th>predicted_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tofu  is  made  from  processed  soybeans</td>\n",
       "      <td>t ow f uw  ih z  m ey dcl  f r em  pcl p r aa ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>author's how had fresh process soybeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i  gave  them  several  choices  and  let  the...</td>\n",
       "      <td>ay  gcl g ey v  dh ah m  s eh v r el  tcl ch o...</td>\n",
       "      <td>Train</td>\n",
       "      <td>are gave warm speak atmosphere annoying let th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>she  had  your  dark  suit  in  greasy  wash  ...</td>\n",
       "      <td>sh iy  hv ae dcl d  y axr  dcl d aa r kcl k  s...</td>\n",
       "      <td>Train</td>\n",
       "      <td>she hood y'all dessert suit eat greasing wash ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>don't  ask  me  to  carry  an  oily  rag  like...</td>\n",
       "      <td>d ow n  ae s kcl  m iy  dx ih  kcl k eh r iy  ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>age waste who it carry an oily rag work gait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a  young  mouse  scampered  across  the  field...</td>\n",
       "      <td>q ax  y ah ng  m aw s  kcl k ae m pcl p axr dx...</td>\n",
       "      <td>Train</td>\n",
       "      <td>al young mask scampered decking over reason an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           Sentence  \\\n",
       "0      0          tofu  is  made  from  processed  soybeans   \n",
       "1      1  i  gave  them  several  choices  and  let  the...   \n",
       "2      2  she  had  your  dark  suit  in  greasy  wash  ...   \n",
       "3      3  don't  ask  me  to  carry  an  oily  rag  like...   \n",
       "4      4  a  young  mouse  scampered  across  the  field...   \n",
       "\n",
       "                                             Phoneme  split  \\\n",
       "0  t ow f uw  ih z  m ey dcl  f r em  pcl p r aa ...  Train   \n",
       "1  ay  gcl g ey v  dh ah m  s eh v r el  tcl ch o...  Train   \n",
       "2  sh iy  hv ae dcl d  y axr  dcl d aa r kcl k  s...  Train   \n",
       "3  d ow n  ae s kcl  m iy  dx ih  kcl k eh r iy  ...  Train   \n",
       "4  q ax  y ah ng  m aw s  kcl k ae m pcl p axr dx...  Train   \n",
       "\n",
       "                                  predicted_sentence  \n",
       "0            author's how had fresh process soybeans  \n",
       "1  are gave warm speak atmosphere annoying let th...  \n",
       "2  she hood y'all dessert suit eat greasing wash ...  \n",
       "3       age waste who it carry an oily rag work gait  \n",
       "4  al young mask scampered decking over reason an...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"predicted_sentence\"] = data[\"Phoneme\"].apply(predict_words)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate the distance between predicted and actual words for each sentence.\n",
    "## 8. Apply the same process in the testing set, provide your inferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:18:13.694280Z",
     "iopub.status.busy": "2022-09-23T02:18:13.693891Z",
     "iopub.status.idle": "2022-09-23T02:18:13.700080Z",
     "shell.execute_reply": "2022-09-23T02:18:13.698783Z",
     "shell.execute_reply.started": "2022-09-23T02:18:13.694249Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sent_distance(sent1,sent2):\n",
    "    distance_word = []\n",
    "    for w1,w2 in zip(sent1.split(),sent2.split()):\n",
    "        dist = word_distances(w1,w2)\n",
    "        distance_word.append(str(dist))\n",
    "    a = \", \".join(distance_word)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T18:12:22.403829Z",
     "iopub.status.busy": "2022-09-17T18:12:22.403397Z",
     "iopub.status.idle": "2022-09-17T18:12:22.413615Z",
     "shell.execute_reply": "2022-09-17T18:12:22.412649Z",
     "shell.execute_reply.started": "2022-09-17T18:12:22.403790Z"
    }
   },
   "outputs": [],
   "source": [
    "def w_distances(w1,w2):\n",
    "    x1 = w2v.wv.get_vector(w1)\n",
    "    x2 = w2v.wv.get_vector(w2)\n",
    "    distance = euclidean(x1,x2)\n",
    "    return round(distance,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T02:18:04.324114Z",
     "iopub.status.busy": "2022-09-23T02:18:04.323747Z",
     "iopub.status.idle": "2022-09-23T02:18:04.329994Z",
     "shell.execute_reply": "2022-09-23T02:18:04.328680Z",
     "shell.execute_reply.started": "2022-09-23T02:18:04.324083Z"
    }
   },
   "outputs": [],
   "source": [
    "def t_distance(sent1,sent2):\n",
    "    total_distance = 0\n",
    "    for w1,w2 in zip(sent1.split(),sent2.split()):\n",
    "        dist = word_distances(w1,w2)\n",
    "        total_distance = total_distance + dist\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T18:12:22.724304Z",
     "iopub.status.busy": "2022-09-17T18:12:22.723380Z",
     "iopub.status.idle": "2022-09-17T18:12:22.733036Z",
     "shell.execute_reply": "2022-09-17T18:12:22.731499Z",
     "shell.execute_reply.started": "2022-09-17T18:12:22.724262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400000000000001"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_distance(\"tofu  is  made  from  processed  soybeans\",\"roles inch voice late process soybeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T18:12:23.447923Z",
     "iopub.status.busy": "2022-09-17T18:12:23.447456Z",
     "iopub.status.idle": "2022-09-17T18:12:23.972238Z",
     "shell.execute_reply": "2022-09-17T18:12:23.970845Z",
     "shell.execute_reply.started": "2022-09-17T18:12:23.447888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>split</th>\n",
       "      <th>predicted_sentence</th>\n",
       "      <th>total_distance</th>\n",
       "      <th>word_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tofu  is  made  from  processed  soybeans</td>\n",
       "      <td>t ow f uw  ih z  m ey dcl  f r em  pcl p r aa ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>author's how had fresh process soybeans</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.13, 0.16, 0.15, 0.12, 0.16, 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i  gave  them  several  choices  and  let  the...</td>\n",
       "      <td>ay  gcl g ey v  dh ah m  s eh v r el  tcl ch o...</td>\n",
       "      <td>Train</td>\n",
       "      <td>are gave warm speak atmosphere annoying let th...</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.13, 0.0, 0.17, 0.15, 0.13, 0.15, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>she  had  your  dark  suit  in  greasy  wash  ...</td>\n",
       "      <td>sh iy  hv ae dcl d  y axr  dcl d aa r kcl k  s...</td>\n",
       "      <td>Train</td>\n",
       "      <td>she hood y'all dessert suit eat greasing wash ...</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0, 0.14, 0.16, 0.14, 0.0, 0.11, 0.12, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>don't  ask  me  to  carry  an  oily  rag  like...</td>\n",
       "      <td>d ow n  ae s kcl  m iy  dx ih  kcl k eh r iy  ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>age waste who it carry an oily rag work gait</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.14, 0.13, 0.15, 0.12, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a  young  mouse  scampered  across  the  field...</td>\n",
       "      <td>q ax  y ah ng  m aw s  kcl k ae m pcl p axr dx...</td>\n",
       "      <td>Train</td>\n",
       "      <td>al young mask scampered decking over reason an...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.15, 0.0, 0.16, 0.0, 0.14, 0.12, 0.14, 0.12, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           Sentence  \\\n",
       "0      0          tofu  is  made  from  processed  soybeans   \n",
       "1      1  i  gave  them  several  choices  and  let  the...   \n",
       "2      2  she  had  your  dark  suit  in  greasy  wash  ...   \n",
       "3      3  don't  ask  me  to  carry  an  oily  rag  like...   \n",
       "4      4  a  young  mouse  scampered  across  the  field...   \n",
       "\n",
       "                                             Phoneme  split  \\\n",
       "0  t ow f uw  ih z  m ey dcl  f r em  pcl p r aa ...  Train   \n",
       "1  ay  gcl g ey v  dh ah m  s eh v r el  tcl ch o...  Train   \n",
       "2  sh iy  hv ae dcl d  y axr  dcl d aa r kcl k  s...  Train   \n",
       "3  d ow n  ae s kcl  m iy  dx ih  kcl k eh r iy  ...  Train   \n",
       "4  q ax  y ah ng  m aw s  kcl k ae m pcl p axr dx...  Train   \n",
       "\n",
       "                                  predicted_sentence  total_distance  \\\n",
       "0            author's how had fresh process soybeans            0.72   \n",
       "1  are gave warm speak atmosphere annoying let th...            1.13   \n",
       "2  she hood y'all dessert suit eat greasing wash ...            1.09   \n",
       "3       age waste who it carry an oily rag work gait            0.79   \n",
       "4  al young mask scampered decking over reason an...            0.97   \n",
       "\n",
       "                                       word_distance  \n",
       "0                  0.13, 0.16, 0.15, 0.12, 0.16, 0.0  \n",
       "1  0.13, 0.0, 0.17, 0.15, 0.13, 0.15, 0.0, 0.0, 0...  \n",
       "2  0.0, 0.14, 0.16, 0.14, 0.0, 0.11, 0.12, 0.0, 0...  \n",
       "3  0.14, 0.13, 0.15, 0.12, 0.0, 0.0, 0.0, 0.0, 0....  \n",
       "4  0.15, 0.0, 0.16, 0.0, 0.14, 0.12, 0.14, 0.12, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"total_distance\"] = data.apply(lambda x: t_distance(x['Sentence'],x[\"predicted_sentence\"]),axis = 1)\n",
    "data[\"word_distance\"] = data.apply(lambda x: w_distance(x['Sentence'],x[\"predicted_sentence\"]),axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T18:13:01.744037Z",
     "iopub.status.busy": "2022-09-17T18:13:01.743538Z",
     "iopub.status.idle": "2022-09-17T18:13:01.753070Z",
     "shell.execute_reply": "2022-09-17T18:13:01.751624Z",
     "shell.execute_reply.started": "2022-09-17T18:13:01.744000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sentence: solid  concrete  blocks  relatively  heavy  and  dense  are  used  for  this  shelter\n",
      "\n",
      "Predicted Sentence:  solid concrete blocks relatively heavy age dense 'em without full they shelter\n",
      "\n",
      "Word distance:  0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.1, 0.14, 0.14, 0.1, 0.0\n",
      "\n",
      "Total distance:  0.61\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actual Sentence: brush  fires  are  common  in  the  dry  underbrush  of  nevada\n",
      "\n",
      "Predicted Sentence:  brush fires pie common inch over dry fatigues bob numbness\n",
      "\n",
      "Word distance:  0.0, 0.0, 0.16, 0.0, 0.18, 0.12, 0.0, 0.18, 0.13, 0.13\n",
      "\n",
      "Total distance:  0.8999999999999999\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actual Sentence: norwegian  sweaters  are  made  of  lamb's  wool\n",
      "\n",
      "Predicted Sentence:  informative surprise art here of lamb's wool\n",
      "\n",
      "Word distance:  0.15, 0.16, 0.17, 0.12, 0.0, 0.0, 0.0\n",
      "\n",
      "Total distance:  0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actual Sentence: she  had  your  dark  suit  in  greasy  wash  water  all  year\n",
      "\n",
      "Predicted Sentence:  she tim y'all dessert suit kind greasing wash tiny all after\n",
      "\n",
      "Word distance:  0.0, 0.13, 0.16, 0.14, 0.0, 0.13, 0.12, 0.0, 0.14, 0.0, 0.14\n",
      "\n",
      "Total distance:  0.9600000000000001\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actual Sentence: don't  ask  me  to  carry  an  oily  rag  like  that\n",
      "\n",
      "Predicted Sentence:  age waste who to carry an valley rag like that\n",
      "\n",
      "Word distance:  0.14, 0.13, 0.15, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0\n",
      "\n",
      "Total distance:  0.5800000000000001\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(\"Actual Sentence:\",data[\"Sentence\"][i])\n",
    "    print(\"Predicted Sentence: \",data[\"predicted_sentence\"][i])\n",
    "    print(\"Word distance: \",data[\"word_distance\"][i])\n",
    "    print(\"Total distance: \",data[\"total_distance\"][i])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
