{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Data","metadata":{}},{"cell_type":"code","source":"path = '../input/ravdess-emotional-speech-audio'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-01T07:20:58.124580Z","iopub.execute_input":"2022-11-01T07:20:58.125055Z","iopub.status.idle":"2022-11-01T07:20:58.155972Z","shell.execute_reply.started":"2022-11-01T07:20:58.124962Z","shell.execute_reply":"2022-11-01T07:20:58.154695Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport random\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:12.405682Z","iopub.execute_input":"2022-11-01T07:21:12.406165Z","iopub.status.idle":"2022-11-01T07:21:12.412522Z","shell.execute_reply.started":"2022-11-01T07:21:12.406132Z","shell.execute_reply":"2022-11-01T07:21:12.411092Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def preprocess(path):\n    file_names = os.listdir(path)\n    male_files = file_names[0::2]\n    female_files = file_names[1::2]\n    audio_files = []\n    for i in male_files:\n        [audio_files.append([os.path.join(i,file), 'happy', 'male']) for file in os.listdir(os.path.join(path, i)) if file.startswith(\"03-01-03\")]\n        [audio_files.append([os.path.join(i,file), 'sad', 'male']) for file in os.listdir(os.path.join(path, i)) if file.startswith(\"03-01-04\")]\n    for i in female_files:\n        [audio_files.append([os.path.join(i,file), 'happy', 'female']) for file in os.listdir(os.path.join(path, i)) if file.startswith(\"03-01-03\")]\n        [audio_files.append([os.path.join(i,file), 'sad', 'female']) for file in os.listdir(os.path.join(path, i)) if file.startswith(\"03-01-04\")]\n    return audio_files","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:13.447465Z","iopub.execute_input":"2022-11-01T07:21:13.447857Z","iopub.status.idle":"2022-11-01T07:21:13.465995Z","shell.execute_reply.started":"2022-11-01T07:21:13.447827Z","shell.execute_reply":"2022-11-01T07:21:13.464776Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"audio_files = preprocess(path)\nprint('audio_files shape: ',np.shape(audio_files))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:17.390384Z","iopub.execute_input":"2022-11-01T07:21:17.390823Z","iopub.status.idle":"2022-11-01T07:21:18.149834Z","shell.execute_reply.started":"2022-11-01T07:21:17.390788Z","shell.execute_reply":"2022-11-01T07:21:18.148421Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"audio_files shape:  (384, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"audio_files = pd.DataFrame(audio_files)\naudio_files = audio_files.sample(frac=1).reset_index(drop=True)\naudio_files.columns = ['Audio Path', 'Emotion', 'Gender']\naudio_files.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:19.526487Z","iopub.execute_input":"2022-11-01T07:21:19.527341Z","iopub.status.idle":"2022-11-01T07:21:19.558531Z","shell.execute_reply.started":"2022-11-01T07:21:19.527275Z","shell.execute_reply":"2022-11-01T07:21:19.557129Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                          Audio Path Emotion Gender\n0  Actor_06/03-01-04-02-02-01-06.wav     sad   male\n1  Actor_13/03-01-04-02-01-02-13.wav     sad   male\n2  Actor_05/03-01-04-01-01-01-05.wav     sad   male\n3  Actor_14/03-01-03-01-01-01-14.wav   happy   male\n4  Actor_22/03-01-03-02-02-01-22.wav   happy   male","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Audio Path</th>\n      <th>Emotion</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Actor_06/03-01-04-02-02-01-06.wav</td>\n      <td>sad</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Actor_13/03-01-04-02-01-02-13.wav</td>\n      <td>sad</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Actor_05/03-01-04-01-01-01-05.wav</td>\n      <td>sad</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Actor_14/03-01-03-01-01-01-14.wav</td>\n      <td>happy</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Actor_22/03-01-03-02-02-01-22.wav</td>\n      <td>happy</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"audio_files.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:24.027059Z","iopub.execute_input":"2022-11-01T07:21:24.027498Z","iopub.status.idle":"2022-11-01T07:21:24.041643Z","shell.execute_reply.started":"2022-11-01T07:21:24.027467Z","shell.execute_reply":"2022-11-01T07:21:24.040271Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Audio Path    384\nEmotion         2\nGender          2\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Extracting MFCC and mel spec features","metadata":{"execution":{"iopub.status.busy":"2022-10-29T01:00:53.222057Z","iopub.execute_input":"2022-10-29T01:00:53.222713Z","iopub.status.idle":"2022-10-29T01:00:53.229202Z","shell.execute_reply.started":"2022-10-29T01:00:53.222662Z","shell.execute_reply":"2022-10-29T01:00:53.227685Z"}}},{"cell_type":"code","source":"import librosa","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:25.229982Z","iopub.execute_input":"2022-11-01T07:21:25.230506Z","iopub.status.idle":"2022-11-01T07:21:27.339900Z","shell.execute_reply.started":"2022-11-01T07:21:25.230469Z","shell.execute_reply":"2022-11-01T07:21:27.338194Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\ndef normalize(x, axis=0):\n    return minmax_scale(x, axis=axis)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:27.541176Z","iopub.execute_input":"2022-11-01T07:21:27.541667Z","iopub.status.idle":"2022-11-01T07:21:27.548310Z","shell.execute_reply.started":"2022-11-01T07:21:27.541624Z","shell.execute_reply":"2022-11-01T07:21:27.546984Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def Data(audio_files, function):\n    data = []\n    for i in range(len(audio_files)):\n        x , sr = librosa.load(os.path.join(path, audio_files['Audio Path'][i]))\n        if function == 'mfcc':\n            data.append(np.mean(librosa.feature.mfcc(y=x, sr=sr, n_mfcc=128).T,axis=0))\n        else:\n            data.append(np.mean(librosa.feature.melspectrogram(y=x, sr=sr, n_mels=128).T,axis=0))\n        \n    data = pd.DataFrame(data)\n    data['class'] = audio_files['Emotion']\n    X = data.iloc[:,:-1]\n    X = normalize(X)\n    y = data.iloc[:,-1]\n    return X,y","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:21:28.570927Z","iopub.execute_input":"2022-11-01T07:21:28.571840Z","iopub.status.idle":"2022-11-01T07:21:28.580728Z","shell.execute_reply.started":"2022-11-01T07:21:28.571797Z","shell.execute_reply":"2022-11-01T07:21:28.579806Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:23:07.891743Z","iopub.execute_input":"2022-11-01T07:23:07.892197Z","iopub.status.idle":"2022-11-01T07:23:07.897906Z","shell.execute_reply.started":"2022-11-01T07:23:07.892166Z","shell.execute_reply":"2022-11-01T07:23:07.896938Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(audio_files['Emotion'])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:23:08.916362Z","iopub.execute_input":"2022-11-01T07:23:08.916828Z","iopub.status.idle":"2022-11-01T07:23:08.938368Z","shell.execute_reply.started":"2022-11-01T07:23:08.916786Z","shell.execute_reply":"2022-11-01T07:23:08.936703Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"LabelEncoder()"},"metadata":{}}]},{"cell_type":"code","source":"X, y = Data(audio_files, 'mfcc')\nX_train_mfcc, X_test_mfcc, y_train_mfcc, y_test_mfcc = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:23:11.453516Z","iopub.execute_input":"2022-11-01T07:23:11.454042Z","iopub.status.idle":"2022-11-01T07:24:53.106801Z","shell.execute_reply.started":"2022-11-01T07:23:11.453998Z","shell.execute_reply":"2022-11-01T07:24:53.104425Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_train_mfcc = encoder.transform(y_train_mfcc)\ny_test_mfcc = encoder.transform(y_test_mfcc)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:24:53.111029Z","iopub.execute_input":"2022-11-01T07:24:53.111836Z","iopub.status.idle":"2022-11-01T07:24:53.121619Z","shell.execute_reply.started":"2022-11-01T07:24:53.111766Z","shell.execute_reply":"2022-11-01T07:24:53.119875Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X, y = Data(audio_files, 'melspectrogram')\nX_train_melspec, X_test_melspec, y_train_melspec, y_test_melspec = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:24:53.124084Z","iopub.execute_input":"2022-11-01T07:24:53.126006Z","iopub.status.idle":"2022-11-01T07:26:26.325123Z","shell.execute_reply.started":"2022-11-01T07:24:53.125927Z","shell.execute_reply":"2022-11-01T07:26:26.323409Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_train_melspec = encoder.transform(y_train_melspec)\ny_test_melspec = encoder.transform(y_test_melspec)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T07:26:26.328740Z","iopub.execute_input":"2022-11-01T07:26:26.329756Z","iopub.status.idle":"2022-11-01T07:26:26.339594Z","shell.execute_reply.started":"2022-11-01T07:26:26.329677Z","shell.execute_reply":"2022-11-01T07:26:26.337905Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:43:38.224571Z","iopub.execute_input":"2022-11-01T08:43:38.225007Z","iopub.status.idle":"2022-11-01T08:43:38.230858Z","shell.execute_reply.started":"2022-11-01T08:43:38.224975Z","shell.execute_reply":"2022-11-01T08:43:38.229417Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"model_mfcc_lr = LogisticRegression(random_state=0).fit(X_train_mfcc, y_train_mfcc)\npred_mfcc_lr = model_mfcc_lr.predict(X_test_mfcc)\nprint(accuracy_score(y_test_mfcc, pred_mfcc_lr))\nprint(confusion_matrix(y_test_mfcc, pred_mfcc_lr))\nprint(classification_report(y_test_mfcc, pred_mfcc_lr))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:43:38.604435Z","iopub.execute_input":"2022-11-01T08:43:38.604859Z","iopub.status.idle":"2022-11-01T08:43:38.665483Z","shell.execute_reply.started":"2022-11-01T08:43:38.604827Z","shell.execute_reply":"2022-11-01T08:43:38.663775Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"0.8110236220472441\n[[54  7]\n [17 49]]\n              precision    recall  f1-score   support\n\n           0       0.76      0.89      0.82        61\n           1       0.88      0.74      0.80        66\n\n    accuracy                           0.81       127\n   macro avg       0.82      0.81      0.81       127\nweighted avg       0.82      0.81      0.81       127\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model_melspec_lr = LogisticRegression(random_state=0).fit(X_train_melspec, y_train_melspec)\npred_melspec_lr = model_melspec_lr.predict(X_test_melspec)\nprint(accuracy_score(y_test_melspec, pred_melspec_lr))\nprint(confusion_matrix(y_test_melspec, pred_melspec_lr))\nprint(classification_report(y_test_melspec, pred_melspec_lr))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:44:12.818172Z","iopub.execute_input":"2022-11-01T08:44:12.818626Z","iopub.status.idle":"2022-11-01T08:44:12.854966Z","shell.execute_reply.started":"2022-11-01T08:44:12.818589Z","shell.execute_reply":"2022-11-01T08:44:12.853744Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"0.7322834645669292\n[[38 23]\n [11 55]]\n              precision    recall  f1-score   support\n\n           0       0.78      0.62      0.69        61\n           1       0.71      0.83      0.76        66\n\n    accuracy                           0.73       127\n   macro avg       0.74      0.73      0.73       127\nweighted avg       0.74      0.73      0.73       127\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CNN","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer, UpSampling2D","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:44:15.255354Z","iopub.execute_input":"2022-11-01T08:44:15.255858Z","iopub.status.idle":"2022-11-01T08:44:15.262107Z","shell.execute_reply.started":"2022-11-01T08:44:15.255816Z","shell.execute_reply":"2022-11-01T08:44:15.260792Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\ncallback = EarlyStopping(monitor='val_loss', patience=3)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:44:15.551896Z","iopub.execute_input":"2022-11-01T08:44:15.552824Z","iopub.status.idle":"2022-11-01T08:44:15.558811Z","shell.execute_reply.started":"2022-11-01T08:44:15.552788Z","shell.execute_reply":"2022-11-01T08:44:15.557173Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel_mfcc_cnn = Sequential()\nmodel_mfcc_cnn.add(InputLayer(input_shape=(16, 8, 1)))\nmodel_mfcc_cnn.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = \"same\"))\nmodel_mfcc_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'))\nmodel_mfcc_cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = \"same\"))\nmodel_mfcc_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'))\nmodel_mfcc_cnn.add(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding = \"same\"))\nmodel_mfcc_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'))\nmodel_mfcc_cnn.add(Flatten())\nmodel_mfcc_cnn.add(Dense(32, activation='relu'))\nmodel_mfcc_cnn.add(Dense(len(audio_files['Emotion'].unique()), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:44:15.848990Z","iopub.execute_input":"2022-11-01T08:44:15.849440Z","iopub.status.idle":"2022-11-01T08:44:15.930680Z","shell.execute_reply.started":"2022-11-01T08:44:15.849404Z","shell.execute_reply":"2022-11-01T08:44:15.929563Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"model_mfcc_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:44:17.145274Z","iopub.execute_input":"2022-11-01T08:44:17.146595Z","iopub.status.idle":"2022-11-01T08:44:17.157238Z","shell.execute_reply.started":"2022-11-01T08:44:17.146513Z","shell.execute_reply":"2022-11-01T08:44:17.155907Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"history_mfcc = model_mfcc_cnn.fit(X_train_mfcc.reshape(X_train_mfcc.shape[0], 16, 8, 1),\n                    y_train_mfcc, epochs=500,\n                    validation_data=(X_test_mfcc.reshape(X_test_mfcc.shape[0], 16, 8, 1), y_test_mfcc),\n                    callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:44:17.866313Z","iopub.execute_input":"2022-11-01T08:44:17.867520Z","iopub.status.idle":"2022-11-01T08:44:19.369716Z","shell.execute_reply.started":"2022-11-01T08:44:17.867477Z","shell.execute_reply":"2022-11-01T08:44:19.368441Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"Epoch 1/500\n9/9 [==============================] - 1s 36ms/step - loss: 0.6924 - accuracy: 0.4903 - val_loss: 0.6903 - val_accuracy: 0.5276\nEpoch 2/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.5214 - val_loss: 0.6972 - val_accuracy: 0.4803\nEpoch 3/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.6908 - accuracy: 0.5097 - val_loss: 0.6954 - val_accuracy: 0.4803\nEpoch 4/500\n9/9 [==============================] - 0s 40ms/step - loss: 0.6880 - accuracy: 0.5097 - val_loss: 0.6912 - val_accuracy: 0.4803\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel_melspec_cnn = Sequential()\nmodel_melspec_cnn.add(InputLayer(input_shape=(16, 8, 1)))\nmodel_melspec_cnn.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding = \"same\"))\nmodel_melspec_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'))\nmodel_melspec_cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = \"same\"))\nmodel_melspec_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'))\nmodel_melspec_cnn.add(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding = \"same\"))\nmodel_melspec_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='valid'))\nmodel_melspec_cnn.add(Flatten())\nmodel_melspec_cnn.add(Dense(32, activation='relu'))\nmodel_melspec_cnn.add(Dense(len(audio_files['Emotion'].unique()), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:45:39.541292Z","iopub.execute_input":"2022-11-01T08:45:39.541789Z","iopub.status.idle":"2022-11-01T08:45:39.624975Z","shell.execute_reply.started":"2022-11-01T08:45:39.541753Z","shell.execute_reply":"2022-11-01T08:45:39.623679Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"model_melspec_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:45:41.095053Z","iopub.execute_input":"2022-11-01T08:45:41.095496Z","iopub.status.idle":"2022-11-01T08:45:41.107619Z","shell.execute_reply.started":"2022-11-01T08:45:41.095461Z","shell.execute_reply":"2022-11-01T08:45:41.106654Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"history_melspec = model_melspec_cnn.fit(X_train_melspec.reshape(X_train_melspec.shape[0], 16, 8, 1),\n                    y_train_melspec, epochs=500,\n                    validation_data=(X_test_melspec.reshape(X_test_melspec.shape[0], 16, 8, 1), y_test_melspec),\n                    callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:45:41.485404Z","iopub.execute_input":"2022-11-01T08:45:41.486433Z","iopub.status.idle":"2022-11-01T08:45:44.876278Z","shell.execute_reply.started":"2022-11-01T08:45:41.486389Z","shell.execute_reply":"2022-11-01T08:45:44.875058Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":134,"outputs":[{"name":"stdout","text":"Epoch 1/500\n9/9 [==============================] - 1s 37ms/step - loss: 0.6892 - accuracy: 0.5136 - val_loss: 0.6828 - val_accuracy: 0.4803\nEpoch 2/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.6760 - accuracy: 0.5097 - val_loss: 0.6694 - val_accuracy: 0.4803\nEpoch 3/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.6638 - accuracy: 0.5097 - val_loss: 0.6511 - val_accuracy: 0.4803\nEpoch 4/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.6437 - accuracy: 0.5097 - val_loss: 0.6276 - val_accuracy: 0.4803\nEpoch 5/500\n9/9 [==============================] - 0s 15ms/step - loss: 0.6337 - accuracy: 0.6187 - val_loss: 0.6127 - val_accuracy: 0.7008\nEpoch 6/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.6213 - accuracy: 0.6576 - val_loss: 0.6071 - val_accuracy: 0.6535\nEpoch 7/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.6220 - accuracy: 0.6031 - val_loss: 0.6018 - val_accuracy: 0.6772\nEpoch 8/500\n9/9 [==============================] - 0s 16ms/step - loss: 0.6127 - accuracy: 0.6887 - val_loss: 0.5971 - val_accuracy: 0.7087\nEpoch 9/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.6089 - accuracy: 0.6965 - val_loss: 0.5957 - val_accuracy: 0.7008\nEpoch 10/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.6047 - accuracy: 0.7043 - val_loss: 0.5877 - val_accuracy: 0.7087\nEpoch 11/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.5971 - accuracy: 0.6965 - val_loss: 0.5804 - val_accuracy: 0.7008\nEpoch 12/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.5896 - accuracy: 0.7004 - val_loss: 0.5780 - val_accuracy: 0.7087\nEpoch 13/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.5864 - accuracy: 0.6965 - val_loss: 0.5675 - val_accuracy: 0.6929\nEpoch 14/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.5761 - accuracy: 0.7004 - val_loss: 0.5595 - val_accuracy: 0.7165\nEpoch 15/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.5685 - accuracy: 0.7004 - val_loss: 0.5507 - val_accuracy: 0.6850\nEpoch 16/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.5808 - accuracy: 0.6809 - val_loss: 0.5444 - val_accuracy: 0.7087\nEpoch 17/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.5549 - accuracy: 0.7004 - val_loss: 0.5485 - val_accuracy: 0.7165\nEpoch 18/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.5642 - accuracy: 0.7121 - val_loss: 0.5399 - val_accuracy: 0.7087\nEpoch 19/500\n9/9 [==============================] - 0s 14ms/step - loss: 0.5903 - accuracy: 0.6693 - val_loss: 0.5627 - val_accuracy: 0.7008\nEpoch 20/500\n9/9 [==============================] - 0s 16ms/step - loss: 0.5730 - accuracy: 0.6887 - val_loss: 0.5411 - val_accuracy: 0.7087\nEpoch 21/500\n9/9 [==============================] - 0s 13ms/step - loss: 0.5479 - accuracy: 0.7160 - val_loss: 0.5443 - val_accuracy: 0.7087\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Autoencoder","metadata":{}},{"cell_type":"code","source":"X, y = Data(audio_files[audio_files['Emotion'] == 'happy'].reset_index(drop=True), 'mfcc')\nX_train_happy, X_test_happy, y_train_happy, y_test_happy = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:45:48.956287Z","iopub.execute_input":"2022-11-01T08:45:48.956745Z","iopub.status.idle":"2022-11-01T08:46:35.215989Z","shell.execute_reply.started":"2022-11-01T08:45:48.956709Z","shell.execute_reply":"2022-11-01T08:46:35.214230Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"X, y = Data(audio_files[audio_files['Emotion'] == 'sad'].reset_index(drop=True), 'mfcc')\nX_train_sad, X_test_sad, y_train_sad, y_test_sad = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:46:35.218614Z","iopub.execute_input":"2022-11-01T08:46:35.219980Z","iopub.status.idle":"2022-11-01T08:47:22.372303Z","shell.execute_reply.started":"2022-11-01T08:46:35.219920Z","shell.execute_reply":"2022-11-01T08:47:22.370819Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nencoder = Sequential()\nencoder.add(InputLayer(input_shape=(16, 8, 1)))\nencoder.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nencoder.add(MaxPooling2D(2, 2))\nencoder.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nencoder.add(MaxPooling2D(2, 2))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:47:22.374153Z","iopub.execute_input":"2022-11-01T08:47:22.376981Z","iopub.status.idle":"2022-11-01T08:48:04.049643Z","shell.execute_reply.started":"2022-11-01T08:47:22.376929Z","shell.execute_reply":"2022-11-01T08:48:04.048200Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"decoder = Sequential()\ndecoder.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\ndecoder.add(UpSampling2D((2, 2)))\ndecoder.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\ndecoder.add(UpSampling2D((2, 2)))\ndecoder.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\ndecoder.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same'))","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:48:04.052421Z","iopub.execute_input":"2022-11-01T08:48:04.052874Z","iopub.status.idle":"2022-11-01T08:48:04.070993Z","shell.execute_reply.started":"2022-11-01T08:48:04.052841Z","shell.execute_reply":"2022-11-01T08:48:04.069589Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"autoencoder = Sequential([encoder, decoder])\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:48:04.072972Z","iopub.execute_input":"2022-11-01T08:48:04.073470Z","iopub.status.idle":"2022-11-01T08:48:04.098847Z","shell.execute_reply.started":"2022-11-01T08:48:04.073426Z","shell.execute_reply":"2022-11-01T08:48:04.097849Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"callback = EarlyStopping(monitor='val_loss', patience=3)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:48:04.100493Z","iopub.execute_input":"2022-11-01T08:48:04.101245Z","iopub.status.idle":"2022-11-01T08:48:04.107077Z","shell.execute_reply.started":"2022-11-01T08:48:04.101201Z","shell.execute_reply":"2022-11-01T08:48:04.105785Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"history_autoencoder = autoencoder.fit(X_train_happy.reshape(X_train_happy.shape[0], 16, 8, 1),\n                                      X_train_happy.reshape(X_train_happy.shape[0], 16, 8, 1),\n                                      epochs=50,\n                                      validation_data=(X_test_happy.reshape(X_test_happy.shape[0], 16, 8, 1),\n                                                       X_test_sad.reshape(X_test_sad.shape[0], 16, 8, 1)))\n                                      #callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:48:04.108511Z","iopub.execute_input":"2022-11-01T08:48:04.109763Z","iopub.status.idle":"2022-11-01T08:48:16.028459Z","shell.execute_reply.started":"2022-11-01T08:48:04.109713Z","shell.execute_reply":"2022-11-01T08:48:16.027455Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Epoch 1/50\n4/4 [==============================] - 1s 113ms/step - loss: 0.6915 - val_loss: 0.6876\nEpoch 2/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6879 - val_loss: 0.6884\nEpoch 3/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6862 - val_loss: 0.6884\nEpoch 4/50\n4/4 [==============================] - 0s 64ms/step - loss: 0.6843 - val_loss: 0.6891\nEpoch 5/50\n4/4 [==============================] - 0s 92ms/step - loss: 0.6823 - val_loss: 0.6897\nEpoch 6/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6800 - val_loss: 0.6906\nEpoch 7/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6773 - val_loss: 0.6916\nEpoch 8/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6720 - val_loss: 0.6981\nEpoch 9/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6720 - val_loss: 0.7034\nEpoch 10/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6697 - val_loss: 0.6991\nEpoch 11/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6688 - val_loss: 0.6986\nEpoch 12/50\n4/4 [==============================] - 0s 63ms/step - loss: 0.6664 - val_loss: 0.7005\nEpoch 13/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6645 - val_loss: 0.7067\nEpoch 14/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6628 - val_loss: 0.7092\nEpoch 15/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6613 - val_loss: 0.7094\nEpoch 16/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6597 - val_loss: 0.7135\nEpoch 17/50\n4/4 [==============================] - 0s 61ms/step - loss: 0.6580 - val_loss: 0.7138\nEpoch 18/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6569 - val_loss: 0.7142\nEpoch 19/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6555 - val_loss: 0.7170\nEpoch 20/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6541 - val_loss: 0.7188\nEpoch 21/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6534 - val_loss: 0.7197\nEpoch 22/50\n4/4 [==============================] - 0s 60ms/step - loss: 0.6525 - val_loss: 0.7189\nEpoch 23/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6515 - val_loss: 0.7221\nEpoch 24/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6507 - val_loss: 0.7230\nEpoch 25/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6500 - val_loss: 0.7216\nEpoch 26/50\n4/4 [==============================] - 0s 60ms/step - loss: 0.6496 - val_loss: 0.7226\nEpoch 27/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6491 - val_loss: 0.7242\nEpoch 28/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6484 - val_loss: 0.7231\nEpoch 29/50\n4/4 [==============================] - 0s 61ms/step - loss: 0.6481 - val_loss: 0.7272\nEpoch 30/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6474 - val_loss: 0.7245\nEpoch 31/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6464 - val_loss: 0.7262\nEpoch 32/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6459 - val_loss: 0.7262\nEpoch 33/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6467 - val_loss: 0.7255\nEpoch 34/50\n4/4 [==============================] - 0s 70ms/step - loss: 0.6456 - val_loss: 0.7262\nEpoch 35/50\n4/4 [==============================] - 0s 60ms/step - loss: 0.6459 - val_loss: 0.7256\nEpoch 36/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6454 - val_loss: 0.7248\nEpoch 37/50\n4/4 [==============================] - 0s 60ms/step - loss: 0.6447 - val_loss: 0.7258\nEpoch 38/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6437 - val_loss: 0.7296\nEpoch 39/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6433 - val_loss: 0.7295\nEpoch 40/50\n4/4 [==============================] - 0s 61ms/step - loss: 0.6422 - val_loss: 0.7308\nEpoch 41/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6418 - val_loss: 0.7302\nEpoch 42/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6415 - val_loss: 0.7293\nEpoch 43/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6410 - val_loss: 0.7318\nEpoch 44/50\n4/4 [==============================] - 0s 62ms/step - loss: 0.6404 - val_loss: 0.7313\nEpoch 45/50\n4/4 [==============================] - 0s 57ms/step - loss: 0.6400 - val_loss: 0.7317\nEpoch 46/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6396 - val_loss: 0.7324\nEpoch 47/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6392 - val_loss: 0.7334\nEpoch 48/50\n4/4 [==============================] - 0s 58ms/step - loss: 0.6386 - val_loss: 0.7352\nEpoch 49/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6382 - val_loss: 0.7362\nEpoch 50/50\n4/4 [==============================] - 0s 59ms/step - loss: 0.6379 - val_loss: 0.7357\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Variational Autoencoder","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-11-01T08:48:54.260439Z","iopub.execute_input":"2022-11-01T08:48:54.260880Z","iopub.status.idle":"2022-11-01T08:48:54.266751Z","shell.execute_reply.started":"2022-11-01T08:48:54.260844Z","shell.execute_reply":"2022-11-01T08:48:54.265305Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","metadata":{"execution":{"iopub.status.busy":"2022-11-01T09:10:30.651855Z","iopub.execute_input":"2022-11-01T09:10:30.652252Z","iopub.status.idle":"2022-11-01T09:10:30.659011Z","shell.execute_reply.started":"2022-11-01T09:10:30.652221Z","shell.execute_reply":"2022-11-01T09:10:30.657849Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"latent_dim = 2\nencoder_inputs = keras.Input(shape=(16, 8, 1))\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(16, activation=\"relu\")(x)\nz_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var])\nencoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-01T09:10:59.607438Z","iopub.execute_input":"2022-11-01T09:10:59.607856Z","iopub.status.idle":"2022-11-01T09:10:59.685721Z","shell.execute_reply.started":"2022-11-01T09:10:59.607824Z","shell.execute_reply":"2022-11-01T09:10:59.684437Z"},"trusted":true},"execution_count":217,"outputs":[{"name":"stdout","text":"Model: \"encoder\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_31 (InputLayer)           [(None, 16, 8, 1)]   0                                            \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 8, 4, 32)     320         input_31[0][0]                   \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 4, 2, 64)     18496       conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nflatten_9 (Flatten)             (None, 512)          0           conv2d_25[0][0]                  \n__________________________________________________________________________________________________\ndense_29 (Dense)                (None, 16)           8208        flatten_9[0][0]                  \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 2)            34          dense_29[0][0]                   \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 2)            34          dense_29[0][0]                   \n__________________________________________________________________________________________________\nsampling_9 (Sampling)           (None, 2)            0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 27,092\nTrainable params: 27,092\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(8 * 4 * 1, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((8, 4, 1))(x)\nx = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\ndecoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-01T09:10:59.943444Z","iopub.execute_input":"2022-11-01T09:10:59.944263Z","iopub.status.idle":"2022-11-01T09:11:00.026154Z","shell.execute_reply.started":"2022-11-01T09:10:59.944215Z","shell.execute_reply":"2022-11-01T09:11:00.024857Z"},"trusted":true},"execution_count":218,"outputs":[{"name":"stdout","text":"Model: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_32 (InputLayer)        [(None, 2)]               0         \n_________________________________________________________________\ndense_30 (Dense)             (None, 32)                96        \n_________________________________________________________________\nreshape_20 (Reshape)         (None, 8, 4, 1)           0         \n_________________________________________________________________\nconv2d_transpose_51 (Conv2DT (None, 16, 8, 64)         640       \n_________________________________________________________________\nconv2d_transpose_52 (Conv2DT (None, 16, 8, 32)         18464     \n_________________________________________________________________\nconv2d_transpose_53 (Conv2DT (None, 16, 8, 1)          289       \n=================================================================\nTotal params: 19,489\nTrainable params: 19,489\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = self.encoder(data)\n            reconstruction = self.decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                tf.reduce_sum(\n                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n                )\n            )\n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-01T09:11:00.217381Z","iopub.execute_input":"2022-11-01T09:11:00.218091Z","iopub.status.idle":"2022-11-01T09:11:00.230678Z","shell.execute_reply.started":"2022-11-01T09:11:00.218053Z","shell.execute_reply":"2022-11-01T09:11:00.229268Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"vae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nhistory = vae.fit(X_train_happy.reshape(X_train_happy.shape[0], 16, 8, 1),\n                  epochs=50)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T09:11:00.486984Z","iopub.execute_input":"2022-11-01T09:11:00.487560Z","iopub.status.idle":"2022-11-01T09:11:04.574841Z","shell.execute_reply.started":"2022-11-01T09:11:00.487512Z","shell.execute_reply":"2022-11-01T09:11:04.573310Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":220,"outputs":[{"name":"stdout","text":"Epoch 1/50\n4/4 [==============================] - 1s 15ms/step - loss: 88.6359 - reconstruction_loss: 88.5823 - kl_loss: 0.0021\nEpoch 2/50\n4/4 [==============================] - 0s 16ms/step - loss: 88.2111 - reconstruction_loss: 88.1171 - kl_loss: 0.0019\nEpoch 3/50\n4/4 [==============================] - 0s 16ms/step - loss: 87.9939 - reconstruction_loss: 88.0466 - kl_loss: 0.0019\nEpoch 4/50\n4/4 [==============================] - 0s 16ms/step - loss: 88.1383 - reconstruction_loss: 88.0727 - kl_loss: 0.0062\nEpoch 5/50\n4/4 [==============================] - 0s 14ms/step - loss: 88.1003 - reconstruction_loss: 87.9381 - kl_loss: 0.0104\nEpoch 6/50\n4/4 [==============================] - 0s 16ms/step - loss: 87.9596 - reconstruction_loss: 87.9649 - kl_loss: 0.0048\nEpoch 7/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.9746 - reconstruction_loss: 87.9474 - kl_loss: 0.0033\nEpoch 8/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.8422 - reconstruction_loss: 87.9042 - kl_loss: 0.0063\nEpoch 9/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.8501 - reconstruction_loss: 87.8339 - kl_loss: 0.0042\nEpoch 10/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.9518 - reconstruction_loss: 87.8986 - kl_loss: 0.0026\nEpoch 11/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.7498 - reconstruction_loss: 87.8745 - kl_loss: 0.0026\nEpoch 12/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.8412 - reconstruction_loss: 87.8300 - kl_loss: 0.0050\nEpoch 13/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.8220 - reconstruction_loss: 87.8645 - kl_loss: 0.0072\nEpoch 14/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.8047 - reconstruction_loss: 87.8182 - kl_loss: 0.0045\nEpoch 15/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.8657 - reconstruction_loss: 87.8509 - kl_loss: 0.0045\nEpoch 16/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.7509 - reconstruction_loss: 87.8003 - kl_loss: 0.0054\nEpoch 17/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.7062 - reconstruction_loss: 87.7430 - kl_loss: 0.0073\nEpoch 18/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.6728 - reconstruction_loss: 87.7507 - kl_loss: 0.0051\nEpoch 19/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.6278 - reconstruction_loss: 87.7121 - kl_loss: 0.0034\nEpoch 20/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.7108 - reconstruction_loss: 87.7417 - kl_loss: 0.0034\nEpoch 21/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.7641 - reconstruction_loss: 87.6845 - kl_loss: 0.0039\nEpoch 22/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.5868 - reconstruction_loss: 87.6787 - kl_loss: 0.0050\nEpoch 23/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.6897 - reconstruction_loss: 87.6996 - kl_loss: 0.0080\nEpoch 24/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.6442 - reconstruction_loss: 87.7048 - kl_loss: 0.0108\nEpoch 25/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.6478 - reconstruction_loss: 87.6105 - kl_loss: 0.0144\nEpoch 26/50\n4/4 [==============================] - 0s 13ms/step - loss: 87.7065 - reconstruction_loss: 87.6115 - kl_loss: 0.0143\nEpoch 27/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.5578 - reconstruction_loss: 87.5847 - kl_loss: 0.0137\nEpoch 28/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.6409 - reconstruction_loss: 87.5596 - kl_loss: 0.0249\nEpoch 29/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.4181 - reconstruction_loss: 87.5421 - kl_loss: 0.0192\nEpoch 30/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.5518 - reconstruction_loss: 87.5126 - kl_loss: 0.0184\nEpoch 31/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.4331 - reconstruction_loss: 87.4159 - kl_loss: 0.0292\nEpoch 32/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.5061 - reconstruction_loss: 87.4849 - kl_loss: 0.0265\nEpoch 33/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.4185 - reconstruction_loss: 87.4004 - kl_loss: 0.0182\nEpoch 34/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.1893 - reconstruction_loss: 87.3565 - kl_loss: 0.0251\nEpoch 35/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.5049 - reconstruction_loss: 87.4724 - kl_loss: 0.0237\nEpoch 36/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.3586 - reconstruction_loss: 87.4370 - kl_loss: 0.0372\nEpoch 37/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.2671 - reconstruction_loss: 87.3188 - kl_loss: 0.0394\nEpoch 38/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.5450 - reconstruction_loss: 87.4806 - kl_loss: 0.0412\nEpoch 39/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.3559 - reconstruction_loss: 87.2576 - kl_loss: 0.0570\nEpoch 40/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.3807 - reconstruction_loss: 87.2775 - kl_loss: 0.0565\nEpoch 41/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.3210 - reconstruction_loss: 87.2517 - kl_loss: 0.0478\nEpoch 42/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.0184 - reconstruction_loss: 87.1256 - kl_loss: 0.0597\nEpoch 43/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.2710 - reconstruction_loss: 87.2598 - kl_loss: 0.0754\nEpoch 44/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.1437 - reconstruction_loss: 87.2140 - kl_loss: 0.0855\nEpoch 45/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.2437 - reconstruction_loss: 87.1639 - kl_loss: 0.0691\nEpoch 46/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.2314 - reconstruction_loss: 87.2166 - kl_loss: 0.0698\nEpoch 47/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.1611 - reconstruction_loss: 87.1126 - kl_loss: 0.0739\nEpoch 48/50\n4/4 [==============================] - 0s 15ms/step - loss: 87.3018 - reconstruction_loss: 87.1798 - kl_loss: 0.0833\nEpoch 49/50\n4/4 [==============================] - 0s 14ms/step - loss: 87.1408 - reconstruction_loss: 87.1076 - kl_loss: 0.0835\nEpoch 50/50\n4/4 [==============================] - 0s 14ms/step - loss: 86.9771 - reconstruction_loss: 87.0705 - kl_loss: 0.0862\n","output_type":"stream"}]}]}