{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxR4X/giKr0Qy9odz77ONC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/mtech-nmims/blob/master/speech-recognition/Lab-Work/20220911-Lab-7-MTech-AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3g9OGVmr_Lt",
        "outputId": "ce2afa3d-53a9-41c7-a572-372c41dca006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading darpa-timit-acousticphonetic-continuous-speech.zip to /content\n",
            "100% 829M/829M [00:07<00:00, 138MB/s]\n",
            "100% 829M/829M [00:07<00:00, 116MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content'\n",
        "!kaggle datasets download -d mfekadu/darpa-timit-acousticphonetic-continuous-speech"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip *.zip"
      ],
      "metadata": {
        "id": "9RKe2TvQsXCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import IPython.display as ipd\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "340_f930sYgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_phoneme = {\n",
        "    'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n",
        "    'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n",
        "    'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n",
        "    'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n",
        "    'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n",
        "    'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n",
        "    'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n",
        "    'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#' \n",
        "}"
      ],
      "metadata": {
        "id": "Sq9FSCjGfbot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def not_phoneme(x):\n",
        "    try:\n",
        "        return imp_phoneme[x]\n",
        "    except:\n",
        "        return 'h#'"
      ],
      "metadata": {
        "id": "1cmvtlZZsuER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phon39 = list(set(imp_phoneme.values()))\n",
        "\n",
        "label_p39 = {}\n",
        "for i, p in enumerate(phon39):\n",
        "    label_p39[p] = i+1"
      ],
      "metadata": {
        "id": "SjDXwsCIr58Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acoustic_features = []\n",
        "label_vectors = []\n",
        "for dirname, _, filenames in os.walk('/content/data/TRAIN/'):\n",
        "    for filename in filenames:\n",
        "        wav_filepath = os.path.join(dirname, filename)\n",
        "        if '.wav' not in wav_filepath:\n",
        "          if '.WAV' in wav_filepath:\n",
        "\n",
        "              ph_filepath = wav_filepath.replace('.WAV', '.PHN')\n",
        "              ph_df = pd.read_csv(ph_filepath, sep=' ', header=None)\n",
        "              ph_df.columns = ['start', 'end', 'phoneme']\n",
        "              ph_df['phoneme'] = ph_df['phoneme'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\"\",x))\n",
        "              ph_df['phoneme'] = ph_df['phoneme'].apply(lambda x: not_phoneme(x))\n",
        "\n",
        "              x , sr = librosa.load(wav_filepath)\n",
        "              mfcc = librosa.feature.mfcc(x, sr=sr, n_mfcc=128).T\n",
        "              db_mfcc = librosa.amplitude_to_db(mfcc, ref=np.max)\n",
        "              db_mfcc = np.mean(mfcc, axis=0)\n",
        "\n",
        "              label = [0 for i in range(39)]\n",
        "              for l in ph_df['phoneme'].unique():\n",
        "                  label[label_p39[l]-1] = 1\n",
        "              label_vectors.append(label)\n",
        "              acoustic_features.append(db_mfcc)"
      ],
      "metadata": {
        "id": "QijJAjwLcriO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acoustic_features_ = np.array(acoustic_features)\n",
        "label_vectors_ = np.array(label_vectors)"
      ],
      "metadata": {
        "id": "2mwGpr6MuP4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acoustic_features_.shape"
      ],
      "metadata": {
        "id": "npoiM9_6_H23",
        "outputId": "ec306e45-0d14-47b2-e2c9-9f6c949cb8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4620, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_size = int(acoustic_features_.shape[0] * 0.80)\n",
        "training_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeuu_lZU7Tep",
        "outputId": "3c813763-ebff-4ab2-ea45-6597be670e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3696"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(128,)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(39, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDuG7GnytCs1",
        "outputId": "d0d18808-7233-4cfd-a0f1-d91a27750755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               66048     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 39)                5031      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,303\n",
            "Trainable params: 235,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(acoustic_features_[:training_size], label_vectors_[:training_size],\n",
        "                    epochs=25,\n",
        "                    validation_data=(acoustic_features_[training_size:], label_vectors_[training_size:]))"
      ],
      "metadata": {
        "id": "M-Jceypl6Rf6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}