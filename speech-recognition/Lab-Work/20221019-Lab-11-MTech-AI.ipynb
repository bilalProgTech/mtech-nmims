{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/mtech-nmims/blob/master/speech-recognition/Lab-Work/20221019-Lab-11-MTech-AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YxJHIxT7sDY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "!kaggle competitions download -c tensorflow-speech-recognition-challenge\n",
        "!unzip *.zip\n",
        "!7za x 'train.7z'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nsqo6ngA_i0A"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
        "import IPython.display as ipd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = []\n",
        "target_series = []\n",
        "for dirname, _, filenames in os.walk('/content/train/audio/'):\n",
        "    for filename in filenames:\n",
        "        filepath = os.path.join(dirname, filename)\n",
        "        target = filepath.split('/')[-2]\n",
        "        if target == 'right' or target == 'seven' or target == 'three':\n",
        "            target_series.append(target)\n",
        "            files.append(filepath)\n",
        "data = pd.DataFrame(target_series, columns=['target'])\n",
        "data['filename'] = files\n",
        "data = data.sample(frac=1)\n",
        "data = data.reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "AG15ULI570Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/train/audio/three/1b4c9b89_nohash_1.wav'\n",
        "x , sr = librosa.load(path)\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Waveplot')\n",
        "librosa.display.waveplot(x, sr=sr)\n",
        "plt.show()\n",
        "ipd.Audio(path)"
      ],
      "metadata": {
        "id": "txRUy7QK9iAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data, test_size=0.20)"
      ],
      "metadata": {
        "id": "gNSC3Aq_-Brw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_count = 0\n",
        "x_train_new = np.zeros((train.shape[0], 256, 20), dtype=np.float64)\n",
        "for count_, path in zip(range(train.shape[0]), train['filename'].values):\n",
        "    x , sr = librosa.load(path)\n",
        "    try:\n",
        "        mfcc = librosa.feature.mfcc(y=x, sr=sr, n_fft=256, n_mfcc=20)\n",
        "        x_train_new[count_, :, :] = mfcc.T\n",
        "    except:\n",
        "        continue\n",
        "        print('Error reading audio')\n",
        "    count_ += 1"
      ],
      "metadata": {
        "id": "xoclxqA070Bq"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_new.shape"
      ],
      "metadata": {
        "id": "aus7tC4t-ryj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "class SpeechAE(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(SpeechAE, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(128, 20, 1)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.UpSampling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.UpSampling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = SpeechAE()"
      ],
      "metadata": {
        "id": "d4_PP50b-4Vt"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "3slXAZcaEVov"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(x_train_new, x_train_new, epochs=20)"
      ],
      "metadata": {
        "id": "RaCqSjQhG86F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sample = autoencoder.encoder(x_train_new[:1,:,]).numpy()\n",
        "decoded_sample = autoencoder.decoder(encoded_sample).numpy()\n",
        "decoded_sample.shape"
      ],
      "metadata": {
        "id": "5lMdxVsfG_WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile\n",
        "mfcc_x = librosa.feature.inverse.mfcc_to_audio(decoded_sample.reshape(128, 20))\n",
        "soundfile.write('example.wav', mfcc_x, 20000)"
      ],
      "metadata": {
        "id": "PR3ezsF2HTI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipd.Audio('example.wav')"
      ],
      "metadata": {
        "id": "NLl__ZVOHrDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyMFPAbFZzaBrM0ubceWnlzA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}